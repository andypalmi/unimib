{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Monitoring NDVI Changes and Segmenting Lost Vegetation\n",
    "\n",
    "## 1. Introduction\n",
    "**Objective**: Monitor the changes in NDVI over the years and segment areas of lost vegetation to classify what they have been converted to using the EuroSAT dataset.\n",
    "\n",
    "**Tools**: Python, Satellite Imagery, NDVI Calculation, EuroSAT Dataset, Machine Learning Models\n",
    "\n",
    "## 2. Data Collection and Preparation\n",
    "### Step 1: Collect Satellite Images\n",
    "- **Sources**: Landsat, Sentinel-2\n",
    "- **Period**: Define the years for monitoring (e.g., 2000-2020)\n",
    "- **Regions**: Define the geographic regions of interest\n",
    "\n",
    "### Step 2: Preprocess Satellite Images\n",
    "- **Cloud Masking**: Remove clouds and shadows\n",
    "- **Radiometric Calibration**: Correct sensor noise and inconsistencies\n",
    "\n",
    "### Step 3: Calculate NDVI\n",
    "- **Formula**: NDVI = (NIR - RED) / (NIR + RED)\n",
    "- **Implementation**: Use libraries like `rasterio` and `numpy`\n",
    "\n",
    "### Step 4: Load EuroSAT Dataset\n",
    "- **Download**: Obtain the EuroSAT dataset\n",
    "- **Categories**: Urban, Agriculture, Forest, etc.\n",
    "\n",
    "## 3. NDVI Analysis\n",
    "### Step 1: Compute Yearly NDVI Maps\n",
    "- **Mean NDVI**: Calculate average NDVI for each year\n",
    "- **Seasonal NDVI**: If needed, calculate for different seasons\n",
    "\n",
    "Table. Quote: **Holben, B.N. (1986). Characteristics of Maximum- Value Composite Images from Temporal AVHRR Data. International Journal of Remote Sensing, 7(11), 1417-1434.** \n",
    "| NDVI Range    | Class                |\n",
    "|----------------|---------------------|\n",
    "| <0             | water               |\n",
    "| 0.03 – 0       | bare soil           |\n",
    "| 0.03 – 0.3     | sparse vegetation   |\n",
    "| 0.3 – 0.5      | moderate vegetation |\n",
    "| >0.5           | dense vegetation    |\n",
    "\n",
    "### Step 2: Identify Changes in NDVI\n",
    "- **Trend Analysis**: Use statistical methods to identify significant changes over the years\n",
    "- **Change Detection**: Highlight areas with significant NDVI reduction\n",
    "\n",
    "## 4. Segmentation of Lost Vegetation\n",
    "### Step 1: Identify Lost Vegetation Tiles\n",
    "- **Thresholding**: Define NDVI thresholds to identify loss\n",
    "- **Mask Creation**: Create masks for areas of NDVI reduction\n",
    "\n",
    "### Step 2: Extract Lost Vegetation Tiles\n",
    "- **Coordinate Extraction**: Get coordinates of identified tiles\n",
    "- **Tile Extraction**: Extract these regions from satellite images\n",
    "\n",
    "## 5. Classification Using EuroSAT\n",
    "### Step 1: Data Preparation\n",
    "- **Tile Labelling**: Label extracted tiles according to EuroSAT categories\n",
    "- **Data Augmentation**: If necessary, augment data to improve model performance\n",
    "\n",
    "### Step 2: Model Selection and Training\n",
    "- **Model**: Choose a suitable classification model (e.g., CNN)\n",
    "- **Training**: Train the model using EuroSAT dataset\n",
    "- **Validation**: Validate model performance on a separate validation set\n",
    "\n",
    "### Step 3: Classification of Lost Vegetation Tiles\n",
    "- **Prediction**: Use the trained model to classify lost vegetation tiles\n",
    "- **Post-processing**: Aggregate and interpret classification results\n",
    "\n",
    "## 6. Results and Analysis\n",
    "### Step 1: Visualization\n",
    "- **NDVI Changes**: Visualize NDVI changes over the years using plots or maps\n",
    "- **Classified Tiles**: Map out classified lost vegetation tiles\n",
    "\n",
    "### Step 2: Interpretation\n",
    "- **Land Use Changes**: Interpret what the lost vegetation has been converted to\n",
    "- **Environmental Impact**: Discuss potential environmental impacts\n",
    "\n",
    "## 7. Conclusion\n",
    "- **Summary**: Summarize key findings\n",
    "- **Future Work**: Suggest possible extensions or improvements\n",
    "\n",
    "## 8. References and Documentation\n",
    "- **References**: List of scholarly articles, datasets, and tools used\n",
    "- **Documentation**: Detailed code comments and project documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 11:28:09.595504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/distribute/combinations.py:33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/distribute/cross_device_ops.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/distribute/cross_device_utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/distribute/values.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:205\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/data/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/data/experimental/__init__.py:97\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/data/experimental/service/__init__.py:419\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/data/util/structure.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_tensor\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m internal\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/ragged/__init__.py:28\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ragged Tensors.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis package defines ops for manipulating ragged tensors (`tf.RaggedTensor`),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mAPI docstring: tensorflow.ragged\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_tensor\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/ragged/ragged_tensor.py:3149\u001b[0m\n\u001b[1;32m   3144\u001b[0m RaggedOrDense \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[Ragged, core_types\u001b[38;5;241m.\u001b[39mTensorLike]\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;66;03m# RaggedTensor must import ragged_ops to ensure that all dispatched ragged ops\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m \u001b[38;5;66;03m# are registered. Ragged ops import RaggedTensor, so import at bottom of the\u001b[39;00m\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;66;03m# file to avoid a partially-initialized module error.\u001b[39;00m\n\u001b[0;32m-> 3149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_ops  \u001b[38;5;66;03m# pylint: disable=unused-import, g-bad-import-order, g-import-not-at-top\u001b[39;00m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/ragged/ragged_ops.py:27\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Import all modules in the `ragged` package that define exported symbols.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mAdditional, import ragged_dispatch (which has the side-effect of registering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mcircular dependencies.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_array_ops\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_autograph\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_batch_gather_ops\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/ragged/ragged_array_ops.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_ragged_array_ops\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sort_ops\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_ragged_shape\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mragged\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ragged_functional_ops\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/sort_ops.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn_ops\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/nn_ops.py:193\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn_grad  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_ops\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stateless_random_ops\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variables \u001b[38;5;28;01mas\u001b[39;00m variables_lib\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/stateless_random_ops.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_random_index_shuffle_ops\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_stateless_random_ops\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_stateless_random_ops_v2\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_ops_util\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/ops/gen_stateless_random_ops_v2.py:352\u001b[0m\n\u001b[1;32m    349\u001b[0m   _result, \u001b[38;5;241m=\u001b[39m _result\n\u001b[1;32m    350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m--> 352\u001b[0m StatelessRandomNormalV2 \u001b[38;5;241m=\u001b[39m tf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_ops.StatelessRandomNormalV2\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_raw_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstateless_random_normal_v2\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstateless_random_normal_v2_eager_fallback\u001b[39m(shape: Annotated[Any, TV_StatelessRandomNormalV2_Tshape], key: Annotated[Any, _atypes\u001b[38;5;241m.\u001b[39mUInt64], counter: Annotated[Any, _atypes\u001b[38;5;241m.\u001b[39mUInt64], alg: Annotated[Any, _atypes\u001b[38;5;241m.\u001b[39mInt32], dtype: TV_StatelessRandomNormalV2_dtype, name, ctx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Annotated[Any, TV_StatelessRandomNormalV2_dtype]:\n\u001b[1;32m    356\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5978\u001b[0m, in \u001b[0;36mto_raw_op\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m   5974\u001b[0m \u001b[38;5;66;03m# Copy `f` to get a new `__dict__`, otherwise `tf_export` will fail\u001b[39;00m\n\u001b[1;32m   5975\u001b[0m \u001b[38;5;66;03m# due to double-registration.\u001b[39;00m\n\u001b[1;32m   5976\u001b[0m f \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mFunctionType(f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__defaults__\u001b[39m,\n\u001b[1;32m   5977\u001b[0m                        f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__closure__\u001b[39m)\n\u001b[0;32m-> 5978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwarg_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/util/tf_export.py:379\u001b[0m, in \u001b[0;36mkwarg_only\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m only takes keyword args (possible keys: \u001b[39m\u001b[38;5;132;01m{kwargs}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease pass these args as kwargs instead.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    374\u001b[0m             f\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mf_argspec\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    375\u001b[0m         )\n\u001b[1;32m    376\u001b[0m     )\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_decorator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorator_argspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_argspec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/util/tf_decorator.py:136\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decorator_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m   decorator_name \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[0;32m--> 136\u001b[0m decorator \u001b[38;5;241m=\u001b[39m \u001b[43mTFDecorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorator_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorator_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecorator_argspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28msetattr\u001b[39m(decorator_func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_tf_decorator\u001b[39m\u001b[38;5;124m'\u001b[39m, decorator)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# the following attributes.\u001b[39;00m\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/util/tf_decorator.py:329\u001b[0m, in \u001b[0;36mTFDecorator.__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    326\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decorator_argspec:\n\u001b[0;32m--> 329\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__signature__ \u001b[38;5;241m=\u001b[39m \u001b[43mfullargspec_to_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorator_argspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(target):\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/unimib/.venv3-12-1/lib/python3.12/site-packages/tensorflow/python/util/tf_decorator.py:86\u001b[0m, in \u001b[0;36mfullargspec_to_signature\u001b[0;34m(fullargspec)\u001b[0m\n\u001b[1;32m     82\u001b[0m parameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m fullargspec\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m     85\u001b[0m   parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 86\u001b[0m       \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m          \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m          \u001b[49m\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOSITIONAL_OR_KEYWORD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m   )\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fullargspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m   parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     95\u001b[0m       inspect\u001b[38;5;241m.\u001b[39mParameter(fullargspec\u001b[38;5;241m.\u001b[39mvarargs, inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mVAR_POSITIONAL)\n\u001b[1;32m     96\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/inspect.py:2729\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2725\u001b[0m VAR_KEYWORD             \u001b[38;5;241m=\u001b[39m _VAR_KEYWORD\n\u001b[1;32m   2727\u001b[0m empty \u001b[38;5;241m=\u001b[39m _empty\n\u001b[0;32m-> 2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, kind, \u001b[38;5;241m*\u001b[39m, default\u001b[38;5;241m=\u001b[39m_empty, annotation\u001b[38;5;241m=\u001b[39m_empty):\n\u001b[1;32m   2730\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2731\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind \u001b[38;5;241m=\u001b[39m _ParameterKind(kind)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "import IPython.display as disp\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import geemap\n",
    "import rasterio\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Earth Engine API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='cementification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCollectionInfoUrl = 'https://storage.googleapis.com/earthengine-stac/catalog/LANDSAT/LANDSAT_LE07_C02_T1_L2.json'\n",
    "r = requests.get(imageCollectionInfoUrl)\n",
    "imageCollInfo = r.json()\n",
    "print(imageCollInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = []\n",
    "\n",
    "for key, value in imageCollInfo.items():\n",
    "    if key == 'summaries':\n",
    "        for key2, value2 in value.items():\n",
    "            if key2 == 'eo:bands':\n",
    "                for band in value2:\n",
    "                    print(f'{band[\"name\"]}: {band}')\n",
    "                    bands.append(band['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'naples'\n",
    "\n",
    "if city == 'milan':\n",
    "    geometry = ee.Geometry.Polygon(\n",
    "        [[[8.967864766059032, 45.73943107755818],\n",
    "          [8.967864766059032, 45.41260677458684],\n",
    "          [9.434783711371532, 45.41260677458684],\n",
    "          [9.434783711371532, 45.73943107755818]]])\n",
    "elif city == 'naples':\n",
    "    geometry = ee.Geometry.Polygon(\n",
    "        [[[13.829280147955982, 41.1031243453332],\n",
    "          [13.829280147955982, 40.51481111232291],\n",
    "          [14.587336788580982, 40.51481111232291],\n",
    "          [14.587336788580982, 41.1031243453332]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Landsat 7 images (from 1999 to 2022, 30m resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute NDVI\n",
    "def compute_ndvi(image):\n",
    "    ndvi = image.normalizedDifference(['SR_B4', 'SR_B3']).rename('NDVI').multiply(10000).toInt16()\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "# Function to filter the collection by season and compute median NDVI\n",
    "def median_ndvi_for_year(year):\n",
    "    start_date = ee.Date.fromYMD(year, 3, 1)\n",
    "    end_date = start_date.advance(6, 'month')\n",
    "    year_collection = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\") \\\n",
    "                .filterBounds(geometry) \\\n",
    "                .filterDate(start_date, end_date) \\\n",
    "                .filter(ee.Filter.lt('CLOUD_COVER', 20)) \\\n",
    "                .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4']) \\\n",
    "                .map(compute_ndvi) \\\n",
    "                .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'NDVI'])\n",
    "\n",
    "    return year_collection.median().clip(geometry).set('year', year)\n",
    "\n",
    "# Generate a list of years\n",
    "years = ee.List.sequence(1999, 2023)\n",
    "\n",
    "year_ndvi = years.map(median_ndvi_for_year).flatten()\n",
    "\n",
    "# Convert the list of images to an image collection\n",
    "years_ndvi_collection = ee.ImageCollection(year_ndvi)\n",
    "\n",
    "# Print the size of the seasonal NDVI collection\n",
    "print(f'Adding {years_ndvi_collection.size().getInfo()} annual layers')\n",
    "\n",
    "# Define visualization parameters for NDVI\n",
    "vis_param_ndvi = {\n",
    "    'min': -1, \n",
    "    'max': 1, \n",
    "    'bands': ['NDVI'],\n",
    "    'palette': ['blue', 'white', 'green']}\n",
    "\n",
    "# Create a progress bar\n",
    "total_iterations = len(years.getInfo())\n",
    "progress_bar = tqdm(total=total_iterations)\n",
    "\n",
    "# Export each annual median NDVI\n",
    "export = False\n",
    "for year in range(1999, 2024): # From 1999 to 2023\n",
    "    year_ndvi = years_ndvi_collection.filter(ee.Filter.eq('year', year)).first()\n",
    "    \n",
    "    # Ensure consistent band data types\n",
    "    # year_ndvi = year_ndvi.toInt16()\n",
    "\n",
    "    # print(f'info about year_ndvi: {year_ndvi.getInfo()} bands {year_ndvi.bandNames().getInfo()}')\n",
    "    \n",
    "    if export:\n",
    "        # Export the image to Google Drive\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=year_ndvi,\n",
    "            description=f\"{city}_{year}\",\n",
    "            folder=\"Environment_exam_annual_20_cloud_no_int16\",\n",
    "            fileNamePrefix=f\"{city}_{year}\",\n",
    "            scale=30,\n",
    "            region=geometry.getInfo()['coordinates'],\n",
    "            fileFormat='GeoTIFF',\n",
    "            skipEmptyTiles=True\n",
    "        )\n",
    "        task.start()\n",
    "    \n",
    "    progress_bar.update()  # Update the progress bar\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment using NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "landsat_path = 'images/landsat_8'\n",
    "for img in os.listdir(landsat_path):\n",
    "    city, year = img.split('_')\n",
    "    year = int(year.split('.')[0])\n",
    "    # Append a dictionary with the data to the list\n",
    "    data.append({'city': city, 'year': year, 'path': f'{landsat_path}/{img}'})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "img_df = pd.DataFrame(data, columns=['city', 'year', 'path', 'water', 'roads_or_urban_areas', 'vegetation'])\n",
    "img_df.sort_values(by=['city', 'year'], inplace=True)\n",
    "img_df.reset_index(drop=True, inplace=True)\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute observed range of NDVI values\n",
    "def compute_observed_ndvi_range(landsat_path):\n",
    "    ndvi_min = np.inf\n",
    "    ndvi_max = -np.inf\n",
    "    \n",
    "    for img in os.listdir(landsat_path):\n",
    "        with rasterio.open(os.path.join(landsat_path, img)) as src:\n",
    "            ndvi = src.read(6)\n",
    "            \n",
    "            current_min = np.nanmin(ndvi)\n",
    "            current_max = np.nanmax(ndvi)\n",
    "            \n",
    "            if current_min < ndvi_min:\n",
    "                ndvi_min = current_min\n",
    "            if current_max > ndvi_max:\n",
    "                ndvi_max = current_max\n",
    "    \n",
    "    return ndvi_min, ndvi_max\n",
    "\n",
    "# Define a function to normalize NDVI values based on observed range and scale to -10000 to 10000\n",
    "def normalize_ndvi(ndvi_img, ndvi_min, ndvi_max):\n",
    "    # Normalize to range [0, 1] based on observed min and max\n",
    "    ndvi_normalized = (ndvi_img - ndvi_min) / (ndvi_max - ndvi_min)\n",
    "    # Scale to -10000 to 10000\n",
    "    ndvi_scaled = ndvi_normalized * 20000 - 10000\n",
    "    return ndvi_scaled\n",
    "\n",
    "# Define a function to classify NDVI values\n",
    "def compute_percentages_by_threshold(ndvi_img, thresholds):\n",
    "    # ndvi_img is a numpy.ndarray and thresholds is a dictionary\n",
    "    # with keys as labels and values as a tuple of (lower_bound, upper_bound)\n",
    "    percentages = {}\n",
    "    for key, value in thresholds.items():\n",
    "        # Create a boolean mask where values within the threshold are True\n",
    "        mask = (ndvi_img > value[0]) & (ndvi_img <= value[1])\n",
    "        # Compute the percentage of True values in the mask\n",
    "        percentage = np.mean(mask) * 100  # Convert fraction to percentage\n",
    "        percentages[key] = percentage\n",
    "    \n",
    "    return percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NDVI thresholds\n",
    "ndvi_thresholds = {\n",
    "    'water': (-1, 0.03),\n",
    "    'roads_or_urban_areas': (0.03, 0.25),\n",
    "    'vegetation': (0.25, 1)\n",
    "}\n",
    "\n",
    "landsat_path = 'images/landsat_8'\n",
    "# Compute observed range of NDVI values across all images\n",
    "ndvi_min, ndvi_max = compute_observed_ndvi_range(landsat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milan_ndvi = []\n",
    "naples_ndvi = []\n",
    "for img in tqdm(img_df['path']):\n",
    "    with rasterio.open(img) as src:\n",
    "        ndvi = src.read(6)\n",
    "        if 'milan' in img:\n",
    "            milan_ndvi.extend(ndvi.flatten())\n",
    "        elif 'naples' in img:\n",
    "            naples_ndvi.extend(ndvi.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    DO NOT RUN ANYMORE!!!!!!!!!\n",
    "\n",
    "'''\n",
    "# def compute_and_add_ndvi(landsat_path, city, binsize=10, epsilon=1e-9):\n",
    "#     ndvi_values = []\n",
    "#     for img in tqdm(os.listdir(landsat_path)):\n",
    "#         if city in img:\n",
    "#             input_img_path = os.path.join(landsat_path, img)\n",
    "#             with rasterio.open(input_img_path, 'r+') as src:\n",
    "#                 print(f'bands {src.descriptions}')\n",
    "                \n",
    "#                 # Store original band names\n",
    "#                 original_descriptions = src.descriptions\n",
    "                \n",
    "#                 red = src.read(4) * 2.75e-5 - 0.2\n",
    "#                 nir = src.read(5) * 2.75e-5 - 0.2\n",
    "                \n",
    "#                 # Adjusted NDVI calculation\n",
    "#                 ndvi = (nir - red) / (nir + red + 2*0.2 + epsilon)  # Add 2*0.2 to denominator to account for offset\n",
    "#                 ndvi_values.extend(ndvi.flatten())\n",
    "\n",
    "#                 # Update metadata to include NDVI band\n",
    "#                 meta = src.meta.copy()  # Create a copy of the metadata\n",
    "#                 meta.update(count=src.count + 1, dtype='float32')\n",
    "\n",
    "#                 # Write data to a new file to avoid issues with updating existing file\n",
    "#                 output_img_path = input_img_path.replace('.tif', '_with_ndvi.tif')\n",
    "\n",
    "#                 with rasterio.open(output_img_path, 'w', **meta) as dst:\n",
    "#                     # Write original bands\n",
    "#                     for i in range(src.count):\n",
    "#                         dst.write(src.read(i + 1), i + 1)\n",
    "#                         dst.set_band_description(i + 1, original_descriptions[i])\n",
    "                    \n",
    "#                     # Write NDVI band\n",
    "#                     dst.write(ndvi.astype(rasterio.float32), src.count + 1)\n",
    "#                     dst.set_band_description(src.count + 1, 'NDVI_normalized')\n",
    "\n",
    "#                 # Replace the original file with the new file\n",
    "#                 os.replace(output_img_path, input_img_path)\n",
    "\n",
    "#     return ndvi_values\n",
    "\n",
    "# # Define paths and city\n",
    "# landsat_path = 'images/landsat_8'\n",
    "# city = 'naples'\n",
    "\n",
    "# # Compute and add NDVI values\n",
    "# ndvi_values = compute_and_add_ndvi(landsat_path, city)\n",
    "\n",
    "# # Verify the changes\n",
    "# for img in os.listdir(landsat_path):\n",
    "#     if city in img:\n",
    "#         with rasterio.open(os.path.join(landsat_path, img)) as src:\n",
    "#             print(f\"Image: {img}\")\n",
    "#             print(f\"Bands: {src.descriptions}\")\n",
    "#             print(f\"Number of bands: {src.count}\")\n",
    "#             print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Function to compute NDVI frequencies\n",
    "def compute_ndvi_frequencies(landsat_path, city, binsize=10, epsilon=1e-9):\n",
    "    ndvi_values = []\n",
    "    for img in tqdm(os.listdir(landsat_path)):\n",
    "        if city in img:\n",
    "            with rasterio.open(os.path.join(landsat_path, img)) as src:\n",
    "                ndvi = src.read(7)\n",
    "                ndvi_values.extend(ndvi.flatten())\n",
    "                \n",
    "    return ndvi_values\n",
    "\n",
    "binsize = 10\n",
    "# Compute NDVI frequencies for Milan images\n",
    "ndvi_milan = compute_ndvi_frequencies(landsat_path='images/landsat_8', city='milan', binsize=binsize)\n",
    "ndvi_naples = compute_ndvi_frequencies(landsat_path='images/landsat_8', city='naples', binsize=binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ndvi_milan, bins=100, color='blue', alpha=0.5, label='Milan')\n",
    "plt.xlabel('NDVI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('NDVI Frequency Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ndvi_naples, bins=100, color='blue', alpha=0.5, label='Naples')\n",
    "plt.xlabel('NDVI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('NDVI Frequency Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape histogram for clustering\n",
    "ndvi_milan = np.array(ndvi_milan).reshape(-1, 1)\n",
    "ndvi_naples = np.array(ndvi_naples).reshape(-1, 1)\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans_milan = KMeans(n_clusters=3, random_state=69420)\n",
    "kmeans_milan.fit(ndvi_milan)\n",
    "print('K means performed for Milan')\n",
    "\n",
    "kmeans_naples = KMeans(n_clusters=3, random_state=69420)\n",
    "kmeans_naples.fit(ndvi_naples)\n",
    "print('K means performed for Naples')\n",
    "\n",
    "# Retrieve cluster centroids (potential thresholds)\n",
    "thresholds_milan = kmeans_milan.cluster_centers_.flatten()\n",
    "thresholds_naples = kmeans_naples.cluster_centers_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram and centroids\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ndvi_milan, bins=100, alpha=0.7, label='NDVI Histogram')\n",
    "plt.axvline(x=thresholds_milan[0], color='r', linestyle='--', label='Threshold 1')\n",
    "plt.axvline(x=thresholds_milan[1], color='g', linestyle='--', label='Threshold 2')\n",
    "plt.axvline(x=thresholds_milan[2], color='b', linestyle='--', label='Threshold 3')\n",
    "plt.xlabel('NDVI Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Milan - NDVI Frequency Distribution with K-means Thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print identified thresholds\n",
    "print(\"Identified thresholds:\", thresholds_milan)\n",
    "\n",
    "# Plot histogram and centroids\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ndvi_naples, bins=100, alpha=0.7, label='NDVI Histogram')\n",
    "plt.axvline(x=thresholds_naples[0], color='r', linestyle='--', label='Threshold 1')\n",
    "plt.axvline(x=thresholds_naples[1], color='g', linestyle='--', label='Threshold 2')\n",
    "plt.axvline(x=thresholds_naples[2], color='b', linestyle='--', label='Threshold 3')\n",
    "plt.xlabel('NDVI Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Naples - NDVI Frequency Distribution with K-means Thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print identified thresholds\n",
    "print(\"Identified thresholds:\", thresholds_naples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_thresholds_milan = {\n",
    "    'water': (-1, thresholds_milan[0]),\n",
    "    'roads_or_urban_areas': (thresholds_milan[0], thresholds_milan[1]),\n",
    "    'vegetation': (thresholds_milan[1], 1)\n",
    "}\n",
    "\n",
    "ndvi_thresholds_naples = {\n",
    "    'water': (-1, thresholds_naples[0]),\n",
    "    'roads_or_urban_areas': (thresholds_naples[0], thresholds_naples[1]),\n",
    "    'vegetation': (thresholds_naples[1], 1)\n",
    "}\n",
    "\n",
    "ndvi_thresholds = {\n",
    "    'water': (-1, -1),\n",
    "    'roads_or_urban_areas': (-1, 0.25),\n",
    "    'vegetation': (0.25, 1)\n",
    "}\n",
    "\n",
    "for img in tqdm(img_df['path']):\n",
    "    with rasterio.open(img) as src:\n",
    "        ndvi = src.read(7)\n",
    "        img_name = img.split('/')[-1]\n",
    "        print(f'{img_name} max ndvi {np.max(ndvi):.3f} min ndvi {np.min(ndvi):.3f} mean ndvi {np.mean(ndvi):.3f}')\n",
    "        percentages = compute_percentages_by_threshold(ndvi, ndvi_thresholds)\n",
    "        # if 'milan' in img:\n",
    "        #     percentages = compute_percentages_by_threshold(ndvi, ndvi_thresholds_milan)\n",
    "        # elif 'naples' in img:\n",
    "        #     percentages = compute_percentages_by_threshold(ndvi, ndvi_thresholds_naples)\n",
    "        # plt.hist(ndvi.flatten(), bins=100, alpha=0.5, label='NDVI')\n",
    "        # plt.title(f'{img} NDVI')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        img_df.loc[img_df['path'] == img, 'water'] = percentages['water']\n",
    "        img_df.loc[img_df['path'] == img, 'roads_or_urban_areas'] = percentages['roads_or_urban_areas']\n",
    "        img_df.loc[img_df['path'] == img, 'vegetation'] = percentages['vegetation']\n",
    "\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/dispms -f images/naples_2017_spring.tif -e 5 -p [3,2,1] -d [0,0,5199,3642]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/dispms -f images/naples_2017_summer.tif -e 4 -p [2,4,3] -d [0,0,5199,3642]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def moving_average_ndvi(landsat_path, city):\n",
    "    # Carica i tuoi dati NDVI in un array 3D\n",
    "    ndvi_3d = []\n",
    "    for img in tqdm(os.listdir(landsat_path)):\n",
    "        if city in img:\n",
    "            with rasterio.open(os.path.join(landsat_path, img)) as src:\n",
    "                ndvi_3d.append(src.read(7))\n",
    "    return ndvi_3d\n",
    "\n",
    "ndvi_3d = moving_average_ndvi(landsat_path='images/landsat_8', city='naples')\n",
    "\n",
    "ndvi_3d = np.array(ndvi_3d)\n",
    "\n",
    "# Applica la media mobile lungo l'asse temporale\n",
    "smoothed_ndvi_3d = np.apply_along_axis(\n",
    "    lambda x: pd.Series(x).rolling(window=3, center=True).mean().values,\n",
    "    axis=0,\n",
    "    arr=ndvi_3d\n",
    ")\n",
    "\n",
    "# Ora smoothed_ndvi_3d contiene i dati NDVI smoothed per ogni pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_thresholds(smoothed_ndvi, n_clusters=3):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(smoothed_ndvi.reshape(-1, 1))\n",
    "    thresholds = np.sort(kmeans.cluster_centers_.flatten())\n",
    "    return thresholds\n",
    "\n",
    "print(smoothed_ndvi_3d.shape)\n",
    "# Esempio di utilizzo\n",
    "thresholds = kmeans_thresholds(smoothed_ndvi_3d.flatten())\n",
    "print(f\"K-means thresholds: {thresholds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.nan_to_num(smoothed_ndvi_3d, copy=False)).sum()\n",
    "np.isnan(smoothed_ndvi_3d).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kmeans_thresholds_with_colored_histogram(smoothed_ndvi, n_clusters=3, bins=100):\n",
    "    # Appiattisci l'array 3D in un array 1D\n",
    "    flat_ndvi = smoothed_ndvi.flatten()\n",
    "    \n",
    "    # Applica K-means\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    labels = kmeans.fit_predict(flat_ndvi.reshape(-1, 1))\n",
    "    \n",
    "    # Ordina i centri dei cluster e le etichette corrispondenti\n",
    "    sorted_indices = np.argsort(kmeans.cluster_centers_.flatten())\n",
    "    sorted_centers = kmeans.cluster_centers_.flatten()[sorted_indices]\n",
    "    sorted_labels = np.argsort(sorted_indices)\n",
    "    \n",
    "    # Calcola l'istogramma\n",
    "    hist, bin_edges = np.histogram(flat_ndvi, bins=bins)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    # Trova i threshold\n",
    "    thresholds = []\n",
    "    for i in range(1, n_clusters):\n",
    "        mask = (bin_centers > sorted_centers[i-1]) & (bin_centers < sorted_centers[i])\n",
    "        if np.sum(mask) > 0:\n",
    "            threshold_index = np.argmin(hist[mask]) + np.where(mask)[0][0]\n",
    "            thresholds.append(bin_centers[threshold_index])\n",
    "    \n",
    "    # Visualizza l'istogramma colorato e i threshold\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    colors = ['red', 'green', 'blue']  # Puoi modificare questi colori se desideri\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        mask = labels == sorted_labels[i]\n",
    "        plt.hist(flat_ndvi[mask], bins=bins, color=colors[i], alpha=0.7, \n",
    "                 label=f'Cluster {i+1}', edgecolor='black')\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        plt.axvline(threshold, color='black', linestyle='dashed', linewidth=2)\n",
    "    \n",
    "    plt.title('NDVI Histogram with K-means Clusters and Thresholds')\n",
    "    plt.xlabel('NDVI')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return thresholds\n",
    "\n",
    "# Esempio di utilizzo\n",
    "thresholds = kmeans_thresholds_with_colored_histogram(smoothed_ndvi_3d)\n",
    "print(f\"K-means thresholds: {thresholds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiles(ndvi):\n",
    "    quantiles = []\n",
    "    for i in range(1, 20):\n",
    "        q = np.quantile(ndvi, i/20)\n",
    "        quantiles.append(q)\n",
    "    return quantiles\n",
    "\n",
    "def plot_quantiles_for_year(landsat_path, city):\n",
    "    for img in os.listdir(landsat_path):\n",
    "        if city in img:\n",
    "            with rasterio.open(os.path.join(landsat_path, img)) as src:\n",
    "                ndvi = src.read(7)\n",
    "                red = src.read(4) * 2.75e-5 - 0.2\n",
    "                green = src.read(3) * 2.75e-5 - 0.2\n",
    "                blue = src.read(2) * 2.75e-5 - 0.2\n",
    "                img = np.stack([red, green, blue], axis=-1)\n",
    "                quantiles = get_quantiles(ndvi.flatten())\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                axes[0].imshow(np.logical_and(ndvi > quantiles[9], ndvi < quantiles[14]), cmap='gray')\n",
    "                axes[1].hist(ndvi.flatten(), bins=100, alpha=0.5, label='NDVI')\n",
    "                for i, q in enumerate(quantiles):\n",
    "                    axes[1].axvline(q, color='r' if i % 2==0 else 'g', linestyle='--', label=f'{(i+1)*5} Quantile')\n",
    "                plt.title(f'{i} Image and NDVI')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "plot_quantiles_for_year(landsat_path='images/landsat_8', city='milan')\n",
    "\n",
    "def get_quantiles_first_year(landsat_path, city, year=2013):\n",
    "    for img in os.listdir(landsat_path):\n",
    "        if city in img and str(year) in img:\n",
    "            with rasterio.open(os.path.join(landsat_path, img)) as src:\n",
    "                ndvi = src.read(7)\n",
    "                quantiles = get_quantiles(ndvi.flatten())\n",
    "                plt.hist(ndvi.flatten(), bins=100, alpha=0.5, label='NDVI')\n",
    "                for i, q in enumerate(quantiles):\n",
    "                    plt.axvline(q, color='r' if i % 2==0 else 'g', linestyle='--', label=f'{(i+1)*5} Quantile')\n",
    "                plt.title(f'{i} Image and NDVI')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                if city == 'naples':\n",
    "                    return quantiles[9], quantiles[14]\n",
    "                elif city == 'milan':\n",
    "                    # TODO return quantiles[10], quantiles[14]\n",
    "\n",
    "landsat_path = 'images/landsat_8'\n",
    "thresh_urban, thresh_vegetation = get_quantiles_first_year(landsat_path=landsat_path, city='naples', year=2013)\n",
    "\n",
    "ndvi_thresholds = {\n",
    "    'water': (-1, -1),\n",
    "    'roads_or_urban_areas': (-1, 0.25),\n",
    "    'vegetation': (0.25, 1)\n",
    "}\n",
    "\n",
    "for img in tqdm(img_df['path']):\n",
    "    with rasterio.open(img) as src:\n",
    "        ndvi = src.read(7)\n",
    "        img_name = img.split('/')[-1]\n",
    "        print(f'{img_name} max ndvi {np.max(ndvi):.3f} min ndvi {np.min(ndvi):.3f} mean ndvi {np.mean(ndvi):.3f}')\n",
    "        percentages = compute_percentages_by_threshold(ndvi, ndvi_thresholds)\n",
    "        img_df.loc[img_df['path'] == img, 'water'] = percentages['water']\n",
    "        img_df.loc[img_df['path'] == img, 'roads_or_urban_areas'] = percentages['roads_or_urban_areas']\n",
    "        img_df.loc[img_df['path'] == img, 'vegetation'] = percentages['vegetation']\n",
    "\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
