{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Index          Layer (type)               Output Shape         Param #\n",
      "========================================================================\n",
      "  1                  Conv2d            [-1, 8, 32, 32]             224\n",
      "  2             BatchNorm2d            [-1, 8, 32, 32]              16\n",
      "  3                  Conv2d           [-1, 16, 32, 32]           1,168\n",
      "  4             BatchNorm2d           [-1, 16, 32, 32]              32\n",
      "  5               MaxPool2d           [-1, 16, 16, 16]               0\n",
      "  6                  Conv2d           [-1, 32, 16, 16]           4,640\n",
      "  7             BatchNorm2d           [-1, 32, 16, 16]              64\n",
      "  8                  Conv2d           [-1, 64, 16, 16]          18,496\n",
      "  9             BatchNorm2d           [-1, 64, 16, 16]             128\n",
      " 10               MaxPool2d             [-1, 64, 8, 8]               0\n",
      " 11                  Conv2d            [-1, 128, 8, 8]          73,856\n",
      " 12             BatchNorm2d            [-1, 128, 8, 8]             256\n",
      " 13                  Conv2d            [-1, 128, 8, 8]         147,584\n",
      " 14             BatchNorm2d            [-1, 128, 8, 8]             256\n",
      " 15               MaxPool2d            [-1, 128, 4, 4]               0\n",
      " 16                  Linear                  [-1, 512]       1,049,088\n",
      " 17                 Dropout                  [-1, 512]               0\n",
      " 18                  Linear                  [-1, 128]          65,664\n",
      " 19                 Dropout                  [-1, 128]               0\n",
      " 20                  Linear                   [-1, 32]           4,128\n",
      " 21                  Linear                   [-1, 10]             330\n",
      "========================================================================\n",
      "Total params: 1,365,930\n",
      "Trainable params: 1,365,930\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.09\n",
      "Params size (MB): 5.21\n",
      "Estimated Total Size (MB): 6.31\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "# Define a neural network class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        self.batchNorm1 = nn.BatchNorm2d(8)       \n",
    "        self.batchNorm2 = nn.BatchNorm2d(16)       \n",
    "        self.batchNorm3 = nn.BatchNorm2d(32)       \n",
    "        self.batchNorm4 = nn.BatchNorm2d(64)       \n",
    "        self.batchNorm5 = nn.BatchNorm2d(128)       \n",
    "        self.batchNorm6 = nn.BatchNorm2d(128)       \n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(p=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchNorm1(self.conv1(x))) # 32 -> 32\n",
    "        x = self.pool(F.relu(self.batchNorm2(self.conv2(x)))) # 32 -> 32 -> 16\n",
    "        x = F.relu(self.batchNorm3(self.conv3(x))) # 16 -> 16\n",
    "        x = self.pool(F.relu(self.batchNorm4(self.conv4(x)))) # 16 -> 16 -> 8\n",
    "        x = F.relu(self.batchNorm5(self.conv5(x))) # 8 -> 8\n",
    "        x = self.pool(F.relu(self.batchNorm6(self.conv6(x)))) # 8 -> 8 -> 4\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Set the device to CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create an instance of the neural network\n",
    "net = Net()\n",
    "\n",
    "# Move the neural network to the specified device (GPU if available)\n",
    "net.to(device)\n",
    "\n",
    "# Define a function to summarize the model\n",
    "def summary(model, input_size, batch_size=-1, device=\"cuda\") -> tuple:\n",
    "    # Define a nested function to register hooks for each module\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            # Get the class name of the module\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            # Create a key for the module in the summary dictionary\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"index\"] = module_idx + 1\n",
    "            summary[m_key][\"layer_type\"] = class_name\n",
    "\n",
    "            # Store the input shape in the summary dictionary\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "\n",
    "            # Store the output shape in the summary dictionary\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            # Calculate the number of parameters in the module\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        # Register the forward hook for the module\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "            and not (module == model)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # Convert the device name to lowercase\n",
    "    device = device.lower()\n",
    "\n",
    "    # Check if the device is valid\n",
    "    assert device in [\n",
    "        \"cuda\",\n",
    "        \"cpu\",\n",
    "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "\n",
    "    # Set the data type based on the device\n",
    "    if device == \"cuda\" and torch.cuda.is_available():\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # Convert input_size to a list if it is a tuple\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # Create random input tensors for each input size\n",
    "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "\n",
    "    # Create an ordered dictionary to store the summary\n",
    "    summary = OrderedDict()\n",
    "\n",
    "    # Create a list to store the hooks\n",
    "    hooks = []\n",
    "\n",
    "    # Register hooks for each module in the model\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # Make a forward pass through the model\n",
    "    model(*x)\n",
    "\n",
    "    # Remove the hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    # Print the summary\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    line_new = \"{:<5}  {:>20}  {:>25} {:>15}\".format(\"Index\", \"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "    print(line_new)\n",
    "    print(\"========================================================================\")\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        line_new = \"{:^5}  {:>20}  {:>25} {:>15}\".format(\n",
    "            layer.split(\"-\")[1],\n",
    "            layer.split(\"-\")[0],\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        print(line_new)\n",
    "\n",
    "    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))\n",
    "    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    print(\"========================================================================\")\n",
    "    print(\"Total params: {0:,}\".format(total_params))\n",
    "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
    "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Input size (MB): %0.2f\" % total_input_size)\n",
    "    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
    "    print(\"Params size (MB): %0.2f\" % total_params_size)\n",
    "    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Call the summary function to summarize the neural network\n",
    "summary_nn = summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Conv2d-1\n",
      "2 BatchNorm2d-2\n",
      "3 Conv2d-3\n",
      "4 BatchNorm2d-4\n",
      "5 MaxPool2d-5\n",
      "6 Conv2d-6\n",
      "7 BatchNorm2d-7\n",
      "8 Conv2d-8\n",
      "9 BatchNorm2d-9\n",
      "10 MaxPool2d-10\n",
      "11 Conv2d-11\n",
      "12 BatchNorm2d-12\n",
      "13 Conv2d-13\n",
      "14 BatchNorm2d-14\n",
      "15 MaxPool2d-15\n",
      "16 Linear-16\n",
      "17 Dropout-17\n",
      "18 Linear-18\n",
      "19 Dropout-19\n",
      "20 Linear-20\n",
      "21 Linear-21\n",
      "index 1\n",
      "layer_type Conv2d\n",
      "input_shape [-1, 3, 32, 32]\n",
      "output_shape [-1, 8, 32, 32]\n",
      "trainable True\n",
      "nb_params tensor(224)\n",
      "index 2\n",
      "layer_type BatchNorm2d\n",
      "input_shape [-1, 8, 32, 32]\n",
      "output_shape [-1, 8, 32, 32]\n",
      "trainable True\n",
      "nb_params tensor(16)\n",
      "index 3\n",
      "layer_type Conv2d\n",
      "input_shape [-1, 8, 32, 32]\n",
      "output_shape [-1, 16, 32, 32]\n",
      "trainable True\n",
      "nb_params tensor(1168)\n",
      "index 4\n",
      "layer_type BatchNorm2d\n",
      "input_shape [-1, 16, 32, 32]\n",
      "output_shape [-1, 16, 32, 32]\n",
      "trainable True\n",
      "nb_params tensor(32)\n",
      "index 5\n",
      "layer_type MaxPool2d\n",
      "input_shape [-1, 16, 32, 32]\n",
      "output_shape [-1, 16, 16, 16]\n",
      "nb_params 0\n",
      "index 6\n",
      "layer_type Conv2d\n",
      "input_shape [-1, 16, 16, 16]\n",
      "output_shape [-1, 32, 16, 16]\n",
      "trainable True\n",
      "nb_params tensor(4640)\n",
      "index 7\n",
      "layer_type BatchNorm2d\n",
      "input_shape [-1, 32, 16, 16]\n",
      "output_shape [-1, 32, 16, 16]\n",
      "trainable True\n",
      "nb_params tensor(64)\n",
      "index 8\n",
      "layer_type Conv2d\n",
      "input_shape [-1, 32, 16, 16]\n",
      "output_shape [-1, 64, 16, 16]\n",
      "trainable True\n",
      "nb_params tensor(18496)\n",
      "index 9\n",
      "layer_type BatchNorm2d\n",
      "input_shape [-1, 64, 16, 16]\n",
      "output_shape [-1, 64, 16, 16]\n",
      "trainable True\n",
      "nb_params tensor(128)\n",
      "index 10\n",
      "layer_type MaxPool2d\n",
      "input_shape [-1, 64, 16, 16]\n",
      "output_shape [-1, 64, 8, 8]\n",
      "nb_params 0\n",
      "index 11\n",
      "layer_type Conv2d\n",
      "input_shape [-1, 64, 8, 8]\n",
      "output_shape [-1, 128, 8, 8]\n",
      "trainable True\n",
      "nb_params tensor(73856)\n",
      "index 12\n",
      "layer_type BatchNorm2d\n",
      "input_shape [-1, 128, 8, 8]\n",
      "output_shape [-1, 128, 8, 8]\n",
      "trainable True\n",
      "nb_params tensor(256)\n",
      "index 13\n",
      "layer_type Conv2d\n",
      "input_shape [-1, 128, 8, 8]\n",
      "output_shape [-1, 128, 8, 8]\n",
      "trainable True\n",
      "nb_params tensor(147584)\n",
      "index 14\n",
      "layer_type BatchNorm2d\n",
      "input_shape [-1, 128, 8, 8]\n",
      "output_shape [-1, 128, 8, 8]\n",
      "trainable True\n",
      "nb_params tensor(256)\n",
      "index 15\n",
      "layer_type MaxPool2d\n",
      "input_shape [-1, 128, 8, 8]\n",
      "output_shape [-1, 128, 4, 4]\n",
      "nb_params 0\n",
      "index 16\n",
      "layer_type Linear\n",
      "input_shape [-1, 2048]\n",
      "output_shape [-1, 512]\n",
      "trainable True\n",
      "nb_params tensor(1049088)\n",
      "index 17\n",
      "layer_type Dropout\n",
      "input_shape [-1, 512]\n",
      "output_shape [-1, 512]\n",
      "nb_params 0\n",
      "index 18\n",
      "layer_type Linear\n",
      "input_shape [-1, 512]\n",
      "output_shape [-1, 128]\n",
      "trainable True\n",
      "nb_params tensor(65664)\n",
      "index 19\n",
      "layer_type Dropout\n",
      "input_shape [-1, 128]\n",
      "output_shape [-1, 128]\n",
      "nb_params 0\n",
      "index 20\n",
      "layer_type Linear\n",
      "input_shape [-1, 128]\n",
      "output_shape [-1, 32]\n",
      "trainable True\n",
      "nb_params tensor(4128)\n",
      "index 21\n",
      "layer_type Linear\n",
      "input_shape [-1, 32]\n",
      "output_shape [-1, 10]\n",
      "trainable True\n",
      "nb_params tensor(330)\n",
      "summary_nn \n",
      " OrderedDict([('Conv2d-1', OrderedDict([('index', 1), ('layer_type', 'Conv2d'), ('input_shape', [-1, 3, 32, 32]), ('output_shape', [-1, 8, 32, 32]), ('trainable', True), ('nb_params', tensor(224))])), ('BatchNorm2d-2', OrderedDict([('index', 2), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 8, 32, 32]), ('output_shape', [-1, 8, 32, 32]), ('trainable', True), ('nb_params', tensor(16))])), ('Conv2d-3', OrderedDict([('index', 3), ('layer_type', 'Conv2d'), ('input_shape', [-1, 8, 32, 32]), ('output_shape', [-1, 16, 32, 32]), ('trainable', True), ('nb_params', tensor(1168))])), ('BatchNorm2d-4', OrderedDict([('index', 4), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 16, 32, 32]), ('output_shape', [-1, 16, 32, 32]), ('trainable', True), ('nb_params', tensor(32))])), ('MaxPool2d-5', OrderedDict([('index', 5), ('layer_type', 'MaxPool2d'), ('input_shape', [-1, 16, 32, 32]), ('output_shape', [-1, 16, 16, 16]), ('nb_params', 0)])), ('Conv2d-6', OrderedDict([('index', 6), ('layer_type', 'Conv2d'), ('input_shape', [-1, 16, 16, 16]), ('output_shape', [-1, 32, 16, 16]), ('trainable', True), ('nb_params', tensor(4640))])), ('BatchNorm2d-7', OrderedDict([('index', 7), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 32, 16, 16]), ('output_shape', [-1, 32, 16, 16]), ('trainable', True), ('nb_params', tensor(64))])), ('Conv2d-8', OrderedDict([('index', 8), ('layer_type', 'Conv2d'), ('input_shape', [-1, 32, 16, 16]), ('output_shape', [-1, 64, 16, 16]), ('trainable', True), ('nb_params', tensor(18496))])), ('BatchNorm2d-9', OrderedDict([('index', 9), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 64, 16, 16]), ('output_shape', [-1, 64, 16, 16]), ('trainable', True), ('nb_params', tensor(128))])), ('MaxPool2d-10', OrderedDict([('index', 10), ('layer_type', 'MaxPool2d'), ('input_shape', [-1, 64, 16, 16]), ('output_shape', [-1, 64, 8, 8]), ('nb_params', 0)])), ('Conv2d-11', OrderedDict([('index', 11), ('layer_type', 'Conv2d'), ('input_shape', [-1, 64, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(73856))])), ('BatchNorm2d-12', OrderedDict([('index', 12), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(256))])), ('Conv2d-13', OrderedDict([('index', 13), ('layer_type', 'Conv2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(147584))])), ('BatchNorm2d-14', OrderedDict([('index', 14), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(256))])), ('MaxPool2d-15', OrderedDict([('index', 15), ('layer_type', 'MaxPool2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 4, 4]), ('nb_params', 0)])), ('Linear-16', OrderedDict([('index', 16), ('layer_type', 'Linear'), ('input_shape', [-1, 2048]), ('output_shape', [-1, 512]), ('trainable', True), ('nb_params', tensor(1049088))])), ('Dropout-17', OrderedDict([('index', 17), ('layer_type', 'Dropout'), ('input_shape', [-1, 512]), ('output_shape', [-1, 512]), ('nb_params', 0)])), ('Linear-18', OrderedDict([('index', 18), ('layer_type', 'Linear'), ('input_shape', [-1, 512]), ('output_shape', [-1, 128]), ('trainable', True), ('nb_params', tensor(65664))])), ('Dropout-19', OrderedDict([('index', 19), ('layer_type', 'Dropout'), ('input_shape', [-1, 128]), ('output_shape', [-1, 128]), ('nb_params', 0)])), ('Linear-20', OrderedDict([('index', 20), ('layer_type', 'Linear'), ('input_shape', [-1, 128]), ('output_shape', [-1, 32]), ('trainable', True), ('nb_params', tensor(4128))])), ('Linear-21', OrderedDict([('index', 21), ('layer_type', 'Linear'), ('input_shape', [-1, 32]), ('output_shape', [-1, 10]), ('trainable', True), ('nb_params', tensor(330))]))]) \n",
      "\n",
      "[OrderedDict([('index', 1), ('layer_type', 'Conv2d'), ('input_shape', [-1, 3, 32, 32]), ('output_shape', [-1, 8, 32, 32]), ('trainable', True), ('nb_params', tensor(224))]), OrderedDict([('index', 2), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 8, 32, 32]), ('output_shape', [-1, 8, 32, 32]), ('trainable', True), ('nb_params', tensor(16))]), OrderedDict([('index', 3), ('layer_type', 'Conv2d'), ('input_shape', [-1, 8, 32, 32]), ('output_shape', [-1, 16, 32, 32]), ('trainable', True), ('nb_params', tensor(1168))]), OrderedDict([('index', 4), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 16, 32, 32]), ('output_shape', [-1, 16, 32, 32]), ('trainable', True), ('nb_params', tensor(32))]), OrderedDict([('index', 5), ('layer_type', 'MaxPool2d'), ('input_shape', [-1, 16, 32, 32]), ('output_shape', [-1, 16, 16, 16]), ('nb_params', 0)]), OrderedDict([('index', 6), ('layer_type', 'Conv2d'), ('input_shape', [-1, 16, 16, 16]), ('output_shape', [-1, 32, 16, 16]), ('trainable', True), ('nb_params', tensor(4640))]), OrderedDict([('index', 7), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 32, 16, 16]), ('output_shape', [-1, 32, 16, 16]), ('trainable', True), ('nb_params', tensor(64))]), OrderedDict([('index', 8), ('layer_type', 'Conv2d'), ('input_shape', [-1, 32, 16, 16]), ('output_shape', [-1, 64, 16, 16]), ('trainable', True), ('nb_params', tensor(18496))]), OrderedDict([('index', 9), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 64, 16, 16]), ('output_shape', [-1, 64, 16, 16]), ('trainable', True), ('nb_params', tensor(128))]), OrderedDict([('index', 10), ('layer_type', 'MaxPool2d'), ('input_shape', [-1, 64, 16, 16]), ('output_shape', [-1, 64, 8, 8]), ('nb_params', 0)]), OrderedDict([('index', 11), ('layer_type', 'Conv2d'), ('input_shape', [-1, 64, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(73856))]), OrderedDict([('index', 12), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(256))]), OrderedDict([('index', 13), ('layer_type', 'Conv2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(147584))]), OrderedDict([('index', 14), ('layer_type', 'BatchNorm2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 8, 8]), ('trainable', True), ('nb_params', tensor(256))]), OrderedDict([('index', 15), ('layer_type', 'MaxPool2d'), ('input_shape', [-1, 128, 8, 8]), ('output_shape', [-1, 128, 4, 4]), ('nb_params', 0)]), OrderedDict([('index', 16), ('layer_type', 'Linear'), ('input_shape', [-1, 2048]), ('output_shape', [-1, 512]), ('trainable', True), ('nb_params', tensor(1049088))]), OrderedDict([('index', 17), ('layer_type', 'Dropout'), ('input_shape', [-1, 512]), ('output_shape', [-1, 512]), ('nb_params', 0)]), OrderedDict([('index', 18), ('layer_type', 'Linear'), ('input_shape', [-1, 512]), ('output_shape', [-1, 128]), ('trainable', True), ('nb_params', tensor(65664))]), OrderedDict([('index', 19), ('layer_type', 'Dropout'), ('input_shape', [-1, 128]), ('output_shape', [-1, 128]), ('nb_params', 0)]), OrderedDict([('index', 20), ('layer_type', 'Linear'), ('input_shape', [-1, 128]), ('output_shape', [-1, 32]), ('trainable', True), ('nb_params', tensor(4128))]), OrderedDict([('index', 21), ('layer_type', 'Linear'), ('input_shape', [-1, 32]), ('output_shape', [-1, 10]), ('trainable', True), ('nb_params', tensor(330))])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>layer_type</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>trainable</th>\n",
       "      <th>nb_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[-1, 3, 32, 32]</td>\n",
       "      <td>[-1, 8, 32, 32]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(224)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BatchNorm2d</td>\n",
       "      <td>[-1, 8, 32, 32]</td>\n",
       "      <td>[-1, 8, 32, 32]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[-1, 8, 32, 32]</td>\n",
       "      <td>[-1, 16, 32, 32]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(1168)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BatchNorm2d</td>\n",
       "      <td>[-1, 16, 32, 32]</td>\n",
       "      <td>[-1, 16, 32, 32]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MaxPool2d</td>\n",
       "      <td>[-1, 16, 32, 32]</td>\n",
       "      <td>[-1, 16, 16, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[-1, 16, 16, 16]</td>\n",
       "      <td>[-1, 32, 16, 16]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(4640)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>BatchNorm2d</td>\n",
       "      <td>[-1, 32, 16, 16]</td>\n",
       "      <td>[-1, 32, 16, 16]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(64)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[-1, 32, 16, 16]</td>\n",
       "      <td>[-1, 64, 16, 16]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(18496)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>BatchNorm2d</td>\n",
       "      <td>[-1, 64, 16, 16]</td>\n",
       "      <td>[-1, 64, 16, 16]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>MaxPool2d</td>\n",
       "      <td>[-1, 64, 16, 16]</td>\n",
       "      <td>[-1, 64, 8, 8]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[-1, 64, 8, 8]</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(73856)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>BatchNorm2d</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(256)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(147584)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>BatchNorm2d</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(256)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>MaxPool2d</td>\n",
       "      <td>[-1, 128, 8, 8]</td>\n",
       "      <td>[-1, 128, 4, 4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[-1, 2048]</td>\n",
       "      <td>[-1, 512]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(1049088)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>[-1, 512]</td>\n",
       "      <td>[-1, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[-1, 512]</td>\n",
       "      <td>[-1, 128]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(65664)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>[-1, 128]</td>\n",
       "      <td>[-1, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[-1, 128]</td>\n",
       "      <td>[-1, 32]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(4128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Linear</td>\n",
       "      <td>[-1, 32]</td>\n",
       "      <td>[-1, 10]</td>\n",
       "      <td>True</td>\n",
       "      <td>tensor(330)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   layer_type       input_shape      output_shape trainable  \\\n",
       "0       1       Conv2d   [-1, 3, 32, 32]   [-1, 8, 32, 32]      True   \n",
       "1       2  BatchNorm2d   [-1, 8, 32, 32]   [-1, 8, 32, 32]      True   \n",
       "2       3       Conv2d   [-1, 8, 32, 32]  [-1, 16, 32, 32]      True   \n",
       "3       4  BatchNorm2d  [-1, 16, 32, 32]  [-1, 16, 32, 32]      True   \n",
       "4       5    MaxPool2d  [-1, 16, 32, 32]  [-1, 16, 16, 16]       NaN   \n",
       "5       6       Conv2d  [-1, 16, 16, 16]  [-1, 32, 16, 16]      True   \n",
       "6       7  BatchNorm2d  [-1, 32, 16, 16]  [-1, 32, 16, 16]      True   \n",
       "7       8       Conv2d  [-1, 32, 16, 16]  [-1, 64, 16, 16]      True   \n",
       "8       9  BatchNorm2d  [-1, 64, 16, 16]  [-1, 64, 16, 16]      True   \n",
       "9      10    MaxPool2d  [-1, 64, 16, 16]    [-1, 64, 8, 8]       NaN   \n",
       "10     11       Conv2d    [-1, 64, 8, 8]   [-1, 128, 8, 8]      True   \n",
       "11     12  BatchNorm2d   [-1, 128, 8, 8]   [-1, 128, 8, 8]      True   \n",
       "12     13       Conv2d   [-1, 128, 8, 8]   [-1, 128, 8, 8]      True   \n",
       "13     14  BatchNorm2d   [-1, 128, 8, 8]   [-1, 128, 8, 8]      True   \n",
       "14     15    MaxPool2d   [-1, 128, 8, 8]   [-1, 128, 4, 4]       NaN   \n",
       "15     16       Linear        [-1, 2048]         [-1, 512]      True   \n",
       "16     17      Dropout         [-1, 512]         [-1, 512]       NaN   \n",
       "17     18       Linear         [-1, 512]         [-1, 128]      True   \n",
       "18     19      Dropout         [-1, 128]         [-1, 128]       NaN   \n",
       "19     20       Linear         [-1, 128]          [-1, 32]      True   \n",
       "20     21       Linear          [-1, 32]          [-1, 10]      True   \n",
       "\n",
       "          nb_params  \n",
       "0       tensor(224)  \n",
       "1        tensor(16)  \n",
       "2      tensor(1168)  \n",
       "3        tensor(32)  \n",
       "4                 0  \n",
       "5      tensor(4640)  \n",
       "6        tensor(64)  \n",
       "7     tensor(18496)  \n",
       "8       tensor(128)  \n",
       "9                 0  \n",
       "10    tensor(73856)  \n",
       "11      tensor(256)  \n",
       "12   tensor(147584)  \n",
       "13      tensor(256)  \n",
       "14                0  \n",
       "15  tensor(1049088)  \n",
       "16                0  \n",
       "17    tensor(65664)  \n",
       "18                0  \n",
       "19     tensor(4128)  \n",
       "20      tensor(330)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "for i, layer in enumerate(summary_nn):\n",
    "    print(i+1, layer)\n",
    "\n",
    "for layer, properties in summary_nn.items():\n",
    "    for key, value in properties.items():\n",
    "        print(key, value)\n",
    "\n",
    "# df_summary = pd.DataFrame.from_dict(summary_nn, columns=['index', 'layer_type', 'input_shape', 'output_shape', 'nb_params'], orient='index')\n",
    "# df_summary\n",
    "\n",
    "print('summary_nn \\n', summary_nn, '\\n')\n",
    "\n",
    "\n",
    "# Extract the inner dictionary values from summary_nn\n",
    "inner_dict = [values for values in summary_nn.values()]\n",
    "print(inner_dict)\n",
    "\n",
    "# Create the DataFrame without the first level of the dictionary\n",
    "df_summary = pd.DataFrame(inner_dict)\n",
    "df_summary\n",
    "# print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import defaultdict\n",
    "\n",
    "color_map = defaultdict(dict)\n",
    "\n",
    "color_map = {\n",
    "    'Linear': \n",
    "        {   'fill': 'blue',\n",
    "            'outline': 'black'},\n",
    "    'Conv1d': \n",
    "        {   'fill': 'purple',\n",
    "            'outline': 'black'},\n",
    "    'Conv2d': \n",
    "        {   'fill': 'orange',\n",
    "            'outline': 'black'},\n",
    "    'Conv3d': \n",
    "        {   'fill': 'red',\n",
    "            'outline': 'black'},\n",
    "    'ConvTranspose1d': \n",
    "        {   'fill': 'green',\n",
    "            'outline': 'black'},\n",
    "    'ConvTranspose2d': \n",
    "        {   'fill': 'teal',\n",
    "            'outline': 'black'},\n",
    "    'ConvTranspose3d': \n",
    "        {   'fill': 'yellow',\n",
    "            'outline': 'black'},\n",
    "    'BatchNorm1d': \n",
    "        {   'fill': 'green',\n",
    "            'outline': 'black'},\n",
    "    'BatchNorm2d': \n",
    "        {   'fill': 'green',\n",
    "            'outline': 'black'},\n",
    "    'BatchNorm3d': \n",
    "        {   'fill': 'green',\n",
    "            'outline': 'black'},\n",
    "    'MaxPool1d': \n",
    "        {   'fill': 'cyan',\n",
    "            'outline': 'black'},\n",
    "    'MaxPool2d': \n",
    "        {   'fill': 'red',\n",
    "            'outline': 'black'},\n",
    "    'MaxPool3d': \n",
    "        {   'fill': 'lime',\n",
    "            'outline': 'black'},\n",
    "    'AvgPool1d': \n",
    "        {   'fill': 'olive',\n",
    "            'outline': 'black'},\n",
    "    'AvgPool2d': \n",
    "        {   'fill': 'navy',\n",
    "            'outline': 'black'},\n",
    "    'AvgPool3d': \n",
    "        {   'fill': 'maroon',\n",
    "            'outline': 'black'},\n",
    "    'Dropout': \n",
    "        {   'fill': 'gray',\n",
    "            'outline': 'black'},\n",
    "    'Dropout2d': \n",
    "        {   'fill': 'gray',\n",
    "            'outline': 'black'},\n",
    "    'Dropout3d': \n",
    "        {   'fill': 'gray',\n",
    "            'outline': 'black'},\n",
    "    'ReLU': \n",
    "        {   'fill': 'darkblue',\n",
    "            'outline': 'black'},\n",
    "    'Sigmoid': \n",
    "        {   'fill': 'darkorange',\n",
    "            'outline': 'black'},\n",
    "    'Tanh': \n",
    "        {   'fill': 'darkred',\n",
    "            'outline': 'black'},\n",
    "    'Softmax': \n",
    "        {   'fill': 'darkgreen',\n",
    "            'outline': 'black'},\n",
    "    'Embedding': \n",
    "        {   'fill': 'darkviolet',\n",
    "            'outline': 'black'},}\n",
    "\n",
    "# def generate_network_diagram(df_summary):\n",
    "#     fig = plt.figure(figsize=(10, 8))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     # Set node positions\n",
    "#     x = df_summary.index\n",
    "#     y = df_summary.index\n",
    "#     z = df_summary['nb_params']\n",
    "\n",
    "#     # Set node colors\n",
    "#     colors = df_summary['layer_type'].map(color_map)\n",
    "\n",
    "#     # Plot nodes\n",
    "#     ax.scatter(x, y, z, c=colors, s=100)\n",
    "\n",
    "#     # Set labels and title\n",
    "#     ax.set_xlabel('Index')\n",
    "#     ax.set_ylabel('Layer Type')\n",
    "#     ax.set_zlabel('Number of Parameters')\n",
    "#     ax.set_title('3D Network Diagram')\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()\n",
    "\n",
    "# generate_network_diagram(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from math import ceil\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from PIL import ImageFont\n",
    "from math import ceil\n",
    "from utils import * # ColorWheel, Box, vertical_image_concat, linear_layout, self_multiply, get_rgba_tuple\n",
    "import aggdraw\n",
    "\n",
    "def layered_view(model: OrderedDict, to_file: str = None, min_z: int = 10, min_xy: int = 10, max_z: int = 400,\n",
    "                 max_xy: int = 2000,\n",
    "                 scale_z: float = 0.1, scale_xy: float = 4, type_ignore: list = None, index_ignore: list = None,\n",
    "                 color_map: dict = None, one_dim_orientation: str = 'z', alpha: float = 0.6,\n",
    "                 background_fill: Any = 'white', draw_volume: bool = True, padding: int = 10,\n",
    "                 spacing: int = 10, draw_funnel: bool = True, shade_step=10, legend: bool = False,\n",
    "                 font: ImageFont = None, font_color: Any = 'black') -> Image:\n",
    "    \"\"\"\n",
    "    Generates a architecture visualization for a given linear keras model (i.e. one input and output tensor for each\n",
    "    layer) in layered style (great for CNN).\n",
    "\n",
    "    :param model: A keras model that will be visualized.\n",
    "    :param to_file: Path to the file to write the created image to. If the image does not exist yet it will be created, else overwritten. Image type is inferred from the file ending. Providing None will disable writing.\n",
    "    :param min_z: Minimum z size in pixel a layer will have.\n",
    "    :param min_xy: Minimum x and y size in pixel a layer will have.\n",
    "    :param max_z: Maximum z size in pixel a layer will have.\n",
    "    :param max_xy: Maximum x and y size in pixel a layer will have.\n",
    "    :param scale_z: Scalar multiplier for the z size of each layer.\n",
    "    :param scale_xy: Scalar multiplier for the x and y size of each layer.\n",
    "    :param type_ignore: List of layer types in the keras model to ignore during drawing.\n",
    "    :param index_ignore: List of layer indexes in the keras model to ignore during drawing.\n",
    "    :param color_map: Dict defining fill and outline for each layer by class type. Will fallback to default values for not specified classes.\n",
    "    :param one_dim_orientation: Axis on which one dimensional layers should be drawn. Can  be 'x', 'y' or 'z'.\n",
    "    :param alpha: Alpha value for the image background.\n",
    "    :param background_fill: Color for the image background. Can be str or (R,G,B,A).\n",
    "    :param draw_volume: Flag to switch between 3D volumetric view and 2D box view.\n",
    "    :param padding: Distance in pixel before the first and after the last layer.\n",
    "    :param spacing: Spacing in pixel between two layers\n",
    "    :param draw_funnel: If set to True, a funnel will be drawn between consecutive layers\n",
    "    :param shade_step: Deviation in lightness for drawing shades (only in volumetric view)\n",
    "    :param legend: Add a legend of the layers to the image\n",
    "    :param font: Font that will be used for the legend. Leaving this set to None, will use the default font.\n",
    "    :param font_color: Color for the font if used. Can be str or (R,G,B,A).\n",
    "\n",
    "    :return: Generated architecture image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over the model to compute bounds and generate boxes\n",
    "\n",
    "    boxes = list()\n",
    "    layer_y = list()\n",
    "    color_wheel = ColorWheel()\n",
    "    current_z = padding\n",
    "    x_off = -1\n",
    "\n",
    "    layer_types = list()\n",
    "\n",
    "    img_height = 0\n",
    "    max_right = 0\n",
    "\n",
    "    if type_ignore is None:\n",
    "        type_ignore = list()\n",
    "\n",
    "    if index_ignore is None:\n",
    "        index_ignore = list()\n",
    "\n",
    "    if color_map is None:\n",
    "        color_map = dict()\n",
    "\n",
    "    for layer_name, layer_info in summary_nn.items():\n",
    "        index = layer_info['index']\n",
    "        layer_type = layer_info['layer_type']\n",
    "        original_output_shape = tuple(layer_info['output_shape'])\n",
    "    \n",
    "        # Ignore layers that the user has opted out to\n",
    "        if layer_type in type_ignore or index in index_ignore:\n",
    "            continue\n",
    "\n",
    "        if layer_type not in layer_types: \n",
    "            layer_types.append(layer_type)\n",
    "\n",
    "        x = min_xy\n",
    "        y = min_xy\n",
    "        z = min_z\n",
    "\n",
    "        output_shape = original_output_shape[1:]  # drop batch size\n",
    "        if len(output_shape) != 1:\n",
    "            output_shape = output_shape[1], output_shape[2], output_shape[0]  # move channels to end\n",
    "        \n",
    "        # print(f'{index} {layer_type} output_shape {output_shape}')\n",
    "\n",
    "        if len(output_shape) == 1:\n",
    "            if one_dim_orientation in ['x', 'y', 'z']:\n",
    "                output_shape = (1, ) * \"xyz\".index(one_dim_orientation) + output_shape\n",
    "            else:\n",
    "                raise ValueError(f\"unsupported orientation: {one_dim_orientation}\")\n",
    "\n",
    "        output_shape = output_shape + (1, ) * (4 - len(output_shape))  # expand 4D.\n",
    "\n",
    "        x = min(max(output_shape[0] * scale_xy, x), max_xy) # -> 128 for 32 output size\n",
    "        y = min(max(output_shape[1] * scale_xy, y), max_xy)  \n",
    "        z = min(max(self_multiply(output_shape[2:]) * scale_z, z), max_z)\n",
    "\n",
    "        box = Box(alpha=alpha)\n",
    "\n",
    "        box.depth = 0\n",
    "\n",
    "        if draw_volume:\n",
    "            box.depth = x / 3\n",
    "\n",
    "        if x_off == -1:\n",
    "            x_off = box.depth / 2\n",
    "\n",
    "        box.text = layer_type + '\\n' + original_output_shape[1:].__str__().strip('()')\n",
    "        \n",
    "        # top left coordinate\n",
    "        box.x1 = current_z - box.depth / 2\n",
    "        box.y1 = box.depth\n",
    "\n",
    "        # bottom right coordinate\n",
    "        box.x2 = box.x1 + z\n",
    "        box.y2 = box.y1 + y\n",
    "\n",
    "        box.fill = color_map.get(layer_type, {'fill': get_random_color()})['fill']\n",
    "        box.outline = color_map.get(layer_type, {'outline': get_random_color()})['fill']\n",
    "        color_map[layer_type] = {'fill': box.fill, 'outline': box.outline}\n",
    "        box.shade = shade_step\n",
    "        boxes.append(box)\n",
    "        layer_y.append(box.y2 - (box.y1 - box.depth))\n",
    "        # Update image bounds\n",
    "        hh = box.y2 - (box.y1 - box.depth)\n",
    "        if hh > img_height:\n",
    "            img_height = hh + padding\n",
    "        if box.x2 + box.depth > max_right:\n",
    "            max_right = box.x2 + box.depth\n",
    "        current_z += z + spacing\n",
    "\n",
    "    # Generate image\n",
    "    img_width = max_right + x_off + padding\n",
    "    img = Image.new('RGBA', (int(ceil(img_width)), int(ceil(img_height))), background_fill)\n",
    "    draw = aggdraw.Draw(img)\n",
    "\n",
    "    # x, y correction (centering)\n",
    "    for i, node in enumerate(boxes):\n",
    "        y_off = (img.height - layer_y[i]) / 2\n",
    "        node.y1 += y_off\n",
    "        node.y2 += y_off\n",
    "\n",
    "        node.x1 += x_off\n",
    "        node.x2 += x_off\n",
    "\n",
    "    # Draw created boxes\n",
    "    last_box = None\n",
    "    for box in boxes:\n",
    "        pen = aggdraw.Pen(get_rgba_tuple(box.outline))\n",
    "        if last_box is not None and draw_funnel:\n",
    "            draw.line([last_box.x2 + last_box.depth, last_box.y1 - last_box.depth,\n",
    "                       box.x1 + box.depth, box.y1 - box.depth], pen)\n",
    "            draw.line([last_box.x2 + last_box.depth, last_box.y2 - last_box.depth,\n",
    "                       box.x1 + box.depth, box.y2 - box.depth], pen)\n",
    "            draw.line([last_box.x2, last_box.y2,\n",
    "                       box.x1, box.y2], pen)\n",
    "            draw.line([last_box.x2, last_box.y1,\n",
    "                       box.x1, box.y1], pen)\n",
    "        box.draw(draw)\n",
    "        last_box = box\n",
    "    draw.flush()\n",
    "\n",
    "    # Create layer color legend\n",
    "    if legend:\n",
    "        if font is None:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        if hasattr(font, 'getsize'):\n",
    "            text_height = font.getsize(\"Ag\")[1]\n",
    "        else:\n",
    "            text_height = font.getbbox(\"Ag\")[3]\n",
    "        cube_size = text_height\n",
    "\n",
    "        depth = 0\n",
    "        if draw_volume:\n",
    "            depth = cube_size // 2\n",
    "\n",
    "        patches = list()\n",
    "\n",
    "        for layer_type in layer_types:\n",
    "            if hasattr(font, 'getsize'):\n",
    "                text_width = font.getsize(layer_type)[0]\n",
    "            else:\n",
    "                text_width = font.getbbox(layer_type)[2]\n",
    "            label_patch_size = (cube_size + depth + spacing + text_width, cube_size + depth)\n",
    "            # this only works if cube_size is bigger than text height\n",
    "\n",
    "            img_box = Image.new('RGBA', label_patch_size, background_fill)\n",
    "            img_text = Image.new('RGBA', label_patch_size, (0, 0, 0, 0))\n",
    "            draw_box = aggdraw.Draw(img_box)\n",
    "            draw_text = ImageDraw.Draw(img_text)\n",
    "\n",
    "            box = Box(alpha=alpha)\n",
    "            box.x1 = 0\n",
    "            box.x2 = box.x1 + cube_size\n",
    "            box.y1 = depth\n",
    "            box.y2 = box.y1 + cube_size\n",
    "            box.depth = depth\n",
    "            box.shade = shade_step\n",
    "            box.fill = color_map.get(layer_type, {'fill': get_random_color()})['fill']\n",
    "            box.outline = color_map.get(layer_type, {'outline': get_random_color()})['fill']\n",
    "            box.draw(draw_box)\n",
    "\n",
    "            text_x = box.x2 + box.depth + spacing\n",
    "            text_y = (label_patch_size[1] - text_height) / 2  # 2D center; use text_height and not the current label!\n",
    "            draw_text.text((text_x, text_y), layer_type, font=font, fill=font_color)\n",
    "\n",
    "            draw_box.flush()\n",
    "            img_box.paste(img_text, mask=img_text)\n",
    "            patches.append(img_box)\n",
    "\n",
    "        legend_image = linear_layout(patches, max_width=img.width, max_height=img.height, padding=padding, spacing=spacing,\n",
    "                                     background_fill=background_fill, horizontal=True)\n",
    "        img = vertical_image_concat(img, legend_image, background_fill=background_fill)\n",
    "\n",
    "    if to_file is not None:\n",
    "        img.save(to_file)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Draw' object has no attribute 'bitmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m type_ignore \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlayered_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayered_view.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_ignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_ignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspacing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 164\u001b[0m, in \u001b[0;36mlayered_view\u001b[0;34m(model, to_file, min_z, min_xy, max_z, max_xy, scale_z, scale_xy, type_ignore, index_ignore, color_map, one_dim_orientation, alpha, background_fill, draw_volume, padding, spacing, draw_funnel, shade_step, legend, font, font_color)\u001b[0m\n\u001b[1;32m    160\u001b[0m         draw\u001b[38;5;241m.\u001b[39mline([last_box\u001b[38;5;241m.\u001b[39mx2, last_box\u001b[38;5;241m.\u001b[39my2,\n\u001b[1;32m    161\u001b[0m                    box\u001b[38;5;241m.\u001b[39mx1, box\u001b[38;5;241m.\u001b[39my2], pen)\n\u001b[1;32m    162\u001b[0m         draw\u001b[38;5;241m.\u001b[39mline([last_box\u001b[38;5;241m.\u001b[39mx2, last_box\u001b[38;5;241m.\u001b[39my1,\n\u001b[1;32m    163\u001b[0m                    box\u001b[38;5;241m.\u001b[39mx1, box\u001b[38;5;241m.\u001b[39my1], pen)\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     last_box \u001b[38;5;241m=\u001b[39m box\n\u001b[1;32m    166\u001b[0m draw\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/unimib/Supervised/code/draw_nn_pytorch/utils.py:88\u001b[0m, in \u001b[0;36mBox.draw\u001b[0;34m(self, draw)\u001b[0m\n\u001b[1;32m     86\u001b[0m draw_text \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(img_text)\n\u001b[1;32m     87\u001b[0m draw_text\u001b[38;5;241m.\u001b[39mtext((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutline, font\u001b[38;5;241m=\u001b[39mfont)  \u001b[38;5;66;03m# Draw the text at (0, 0) position\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbitmap\u001b[49m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my1), img_text, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutline)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Draw' object has no attribute 'bitmap'"
     ]
    }
   ],
   "source": [
    "type_ignore = []\n",
    "layered_view(summary_nn, to_file='layered_view.png', type_ignore=type_ignore, legend=True, padding=25, spacing=20, color_map=color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
