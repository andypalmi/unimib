digraph {
	graph [size="29.25,29.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140199154840128 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	140199159495360 [label=AddmmBackward0]
	140199159496128 -> 140199159495360
	140197427458704 [label="fc4.bias
 (10)" fillcolor=lightblue]
	140197427458704 -> 140199159496128
	140199159496128 [label=AccumulateGrad]
	140199159495312 -> 140199159495360
	140199159495312 [label=LeakyReluBackward0]
	140198450775904 -> 140199159495312
	140198450775904 [label=AddmmBackward0]
	140198450778448 -> 140198450775904
	140197427460544 [label="fc3.bias
 (32)" fillcolor=lightblue]
	140197427460544 -> 140198450778448
	140198450778448 [label=AccumulateGrad]
	140198450789200 -> 140198450775904
	140198450789200 [label=LeakyReluBackward0]
	140199158272096 -> 140198450789200
	140199158272096 [label=AddmmBackward0]
	140199158279872 -> 140199158272096
	140197427460864 [label="fc2.bias
 (128)" fillcolor=lightblue]
	140197427460864 -> 140199158279872
	140199158279872 [label=AccumulateGrad]
	140199158280160 -> 140199158272096
	140199158280160 [label=LeakyReluBackward0]
	140199158278336 -> 140199158280160
	140199158278336 [label=AddmmBackward0]
	140199158271136 -> 140199158278336
	140197427461744 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140197427461744 -> 140199158271136
	140199158271136 [label=AccumulateGrad]
	140199158277184 -> 140199158278336
	140199158277184 [label=ViewBackward0]
	140199158272624 -> 140199158277184
	140199158272624 [label=MaxPool2DWithIndicesBackward0]
	140199158271376 -> 140199158272624
	140199158271376 [label=LeakyReluBackward0]
	140199158271664 -> 140199158271376
	140199158271664 [label=CudnnBatchNormBackward0]
	140199158274544 -> 140199158271664
	140199158274544 [label=ConvolutionBackward0]
	140199158271328 -> 140199158274544
	140199158271328 [label=LeakyReluBackward0]
	140199158277376 -> 140199158271328
	140199158277376 [label=CudnnBatchNormBackward0]
	140199158274784 -> 140199158277376
	140199158274784 [label=ConvolutionBackward0]
	140199158278672 -> 140199158274784
	140199158278672 [label=MaxPool2DWithIndicesBackward0]
	140199158279056 -> 140199158278672
	140199158279056 [label=LeakyReluBackward0]
	140199158271952 -> 140199158279056
	140199158271952 [label=CudnnBatchNormBackward0]
	140199158273728 -> 140199158271952
	140199158273728 [label=ConvolutionBackward0]
	140199158274016 -> 140199158273728
	140199158274016 [label=ReluBackward0]
	140199158279200 -> 140199158274016
	140199158279200 [label=CudnnBatchNormBackward0]
	140199158279584 -> 140199158279200
	140199158279584 [label=ConvolutionBackward0]
	140199158272528 -> 140199158279584
	140199158272528 [label=MaxPool2DWithIndicesBackward0]
	140199158274160 -> 140199158272528
	140199158274160 [label=LeakyReluBackward0]
	140199158271472 -> 140199158274160
	140199158271472 [label=CudnnBatchNormBackward0]
	140199158271424 -> 140199158271472
	140199158271424 [label=ConvolutionBackward0]
	140199158279632 -> 140199158271424
	140199158279632 [label=LeakyReluBackward0]
	140199158272912 -> 140199158279632
	140199158272912 [label=CudnnBatchNormBackward0]
	140199158278624 -> 140199158272912
	140199158278624 [label=ConvolutionBackward0]
	140199158273344 -> 140199158278624
	140197427455664 [label="conv1.weight
 (8, 3, 3, 3)" fillcolor=lightblue]
	140197427455664 -> 140199158273344
	140199158273344 [label=AccumulateGrad]
	140199158272288 -> 140199158278624
	140197427457184 [label="conv1.bias
 (8)" fillcolor=lightblue]
	140197427457184 -> 140199158272288
	140199158272288 [label=AccumulateGrad]
	140199158280400 -> 140199158272912
	140197417558688 [label="batchNorm1.weight
 (8)" fillcolor=lightblue]
	140197417558688 -> 140199158280400
	140199158280400 [label=AccumulateGrad]
	140199158279536 -> 140199158272912
	140197427449664 [label="batchNorm1.bias
 (8)" fillcolor=lightblue]
	140197427449664 -> 140199158279536
	140199158279536 [label=AccumulateGrad]
	140199158273680 -> 140199158271424
	140197427457824 [label="conv2.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	140197427457824 -> 140199158273680
	140199158273680 [label=AccumulateGrad]
	140199158273920 -> 140199158271424
	140197427457424 [label="conv2.bias
 (16)" fillcolor=lightblue]
	140197427457424 -> 140199158273920
	140199158273920 [label=AccumulateGrad]
	140199158279152 -> 140199158271472
	140197417558448 [label="batchNorm2.weight
 (16)" fillcolor=lightblue]
	140197417558448 -> 140199158279152
	140199158279152 [label=AccumulateGrad]
	140199158273056 -> 140199158271472
	140197427449584 [label="batchNorm2.bias
 (16)" fillcolor=lightblue]
	140197427449584 -> 140199158273056
	140199158273056 [label=AccumulateGrad]
	140199158272240 -> 140199158279584
	140197427456784 [label="conv3.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140197427456784 -> 140199158272240
	140199158272240 [label=AccumulateGrad]
	140199158272336 -> 140199158279584
	140197427456704 [label="conv3.bias
 (32)" fillcolor=lightblue]
	140197427456704 -> 140199158272336
	140199158272336 [label=AccumulateGrad]
	140199158273392 -> 140199158279200
	140197427452224 [label="batchNorm3.weight
 (32)" fillcolor=lightblue]
	140197427452224 -> 140199158273392
	140199158273392 [label=AccumulateGrad]
	140199158274256 -> 140199158279200
	140197427451584 [label="batchNorm3.bias
 (32)" fillcolor=lightblue]
	140197427451584 -> 140199158274256
	140199158274256 [label=AccumulateGrad]
	140199158271712 -> 140199158273728
	140197427458064 [label="conv4.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140197427458064 -> 140199158271712
	140199158271712 [label=AccumulateGrad]
	140199158272384 -> 140199158273728
	140197427457984 [label="conv4.bias
 (64)" fillcolor=lightblue]
	140197427457984 -> 140199158272384
	140199158272384 [label=AccumulateGrad]
	140199158271616 -> 140199158271952
	140197427451024 [label="batchNorm4.weight
 (64)" fillcolor=lightblue]
	140197427451024 -> 140199158271616
	140199158271616 [label=AccumulateGrad]
	140199158273200 -> 140199158271952
	140197427451984 [label="batchNorm4.bias
 (64)" fillcolor=lightblue]
	140197427451984 -> 140199158273200
	140199158273200 [label=AccumulateGrad]
	140199158274064 -> 140199158274784
	140197427457664 [label="conv5.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140197427457664 -> 140199158274064
	140199158274064 [label=AccumulateGrad]
	140199158278000 -> 140199158274784
	140197427457584 [label="conv5.bias
 (128)" fillcolor=lightblue]
	140197427457584 -> 140199158278000
	140199158278000 [label=AccumulateGrad]
	140199158272864 -> 140199158277376
	140197427453104 [label="batchNorm5.weight
 (128)" fillcolor=lightblue]
	140197427453104 -> 140199158272864
	140199158272864 [label=AccumulateGrad]
	140199158279680 -> 140199158277376
	140197427454624 [label="batchNorm5.bias
 (128)" fillcolor=lightblue]
	140197427454624 -> 140199158279680
	140199158279680 [label=AccumulateGrad]
	140199158278960 -> 140199158274544
	140197427457344 [label="conv6.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140197427457344 -> 140199158278960
	140199158278960 [label=AccumulateGrad]
	140199158279008 -> 140199158274544
	140197427458224 [label="conv6.bias
 (128)" fillcolor=lightblue]
	140197427458224 -> 140199158279008
	140199158279008 [label=AccumulateGrad]
	140199158274352 -> 140199158271664
	140197427454864 [label="batchNorm6.weight
 (128)" fillcolor=lightblue]
	140197427454864 -> 140199158274352
	140199158274352 [label=AccumulateGrad]
	140199158271568 -> 140199158271664
	140197427455424 [label="batchNorm6.bias
 (128)" fillcolor=lightblue]
	140197427455424 -> 140199158271568
	140199158271568 [label=AccumulateGrad]
	140199158278096 -> 140199158278336
	140199158278096 [label=TBackward0]
	140199158274304 -> 140199158278096
	140197427455744 [label="fc1.weight
 (512, 2048)" fillcolor=lightblue]
	140197427455744 -> 140199158274304
	140199158274304 [label=AccumulateGrad]
	140199158278240 -> 140199158272096
	140199158278240 [label=TBackward0]
	140199158277328 -> 140199158278240
	140197427461584 [label="fc2.weight
 (128, 512)" fillcolor=lightblue]
	140197427461584 -> 140199158277328
	140199158277328 [label=AccumulateGrad]
	140198450787376 -> 140198450775904
	140198450787376 [label=TBackward0]
	140199158272048 -> 140198450787376
	140197427460224 [label="fc3.weight
 (32, 128)" fillcolor=lightblue]
	140197427460224 -> 140199158272048
	140199158272048 [label=AccumulateGrad]
	140198450790256 -> 140199159495360
	140198450790256 [label=TBackward0]
	140198450788240 -> 140198450790256
	140197427459664 [label="fc4.weight
 (10, 32)" fillcolor=lightblue]
	140197427459664 -> 140198450788240
	140198450788240 [label=AccumulateGrad]
	140199159495360 -> 140199154840128
}
