{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shbM3zJAuPI9"
      },
      "source": [
        "In this lab you will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function and optimizer\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "Using ``torchvision``, itâ€™s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf9I_7NdzTf6"
      },
      "source": [
        "How to install a different version of a package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ZhoQ3vuPI_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F0vCe0kzcJ9"
      },
      "source": [
        "Use GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bun1lQdwoqy"
      },
      "outputs": [],
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZyKEHctuPI_"
      },
      "source": [
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "   \n",
        "The output of [torchvision datasets](https://pytorch.org/vision/stable/datasets.html#datasets) are PILImage images of range [0, 1].\n",
        "We [transform](https://pytorch.org/vision/stable/transforms.html) them to normalized Tensors. Then we call the [dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV92dK3ruPI_"
      },
      "outputs": [],
      "source": [
        "# Define data transformation pipeline\n",
        "transform = transforms.Compose([\n",
        "    # Convert PIL images to PyTorch tensors\n",
        "    transforms.ToTensor(),\n",
        "    # Normalize pixel values\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 training dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Create data loader for training data with batch size 4 and shuffling\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# Load the CIFAR-10 testing dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Create data loader for testing data with batch size 1 and shuffling\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "\n",
        "# Define class labels for CIFAR-10 dataset\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nB4FDsouPJA"
      },
      "source": [
        "Let us [show](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow) some of the training images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVCb2s_QuPJA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # Import library for plotting\n",
        "import numpy as np  # Import library for numerical computations\n",
        "from collections import Counter  # Import Counter for counting elements\n",
        "\n",
        "# Function to display an image\n",
        "def imshow(image):\n",
        "    mean=torch.tensor([0.485, 0.456, 0.406])\n",
        "    std=torch.tensor([0.229, 0.224, 0.225])\n",
        "\n",
        "    # Unnormalize the image channels to [0, 1]\n",
        "    image = image.mul(std.unsqueeze(1).unsqueeze(2))  # More efficient element-wise multiplication\n",
        "    image = image.add(mean.unsqueeze(1).unsqueeze(2))  # Efficient element-wise addition\n",
        "\n",
        "    image= image.clamp(0, 1)\n",
        "\n",
        "    # Convert the tensor to a NumPy array\n",
        "    npimg = image.numpy()\n",
        "    # Plot the image using matplotlib\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Transpose for correct display\n",
        "\n",
        "# ------------------ Train Loader Section ------------------\n",
        "\n",
        "print(\"Train loader:\")\n",
        "\n",
        "# Count the frequency of each class in the training set\n",
        "stat = dict(Counter(trainset.targets))\n",
        "\n",
        "# Create a new dictionary with class names as keys\n",
        "new_stat = stat.copy()\n",
        "for k in stat.keys():\n",
        "    new_stat[classes[k]] = stat[k]\n",
        "    del new_stat[k]\n",
        "\n",
        "# Print the length of the train loader (number of batches)\n",
        "print(len(trainloader))\n",
        "\n",
        "# Print the class distribution in the training set\n",
        "print(new_stat)\n",
        "\n",
        "# Get a batch of random training images and their labels\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Print the shape of the image tensor (batch_size, channels, height, width)\n",
        "print(images.shape)\n",
        "\n",
        "# Display the images using the imshow function\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# Print the labels of the images\n",
        "print(' '.join('%s' % classes[labels[j]] for j in range(4)))  # Print labels for 4 images\n",
        "\n",
        "# ------------------ Test Loader Section ------------------\n",
        "\n",
        "print(\"\\nTest loader:\")\n",
        "\n",
        "# Similar steps for the test loader\n",
        "stat = dict(Counter(testset.targets))\n",
        "new_stat = stat.copy()\n",
        "for k in stat.keys():\n",
        "    new_stat[classes[k]] = stat[k]\n",
        "    del new_stat[k]\n",
        "\n",
        "print(len(testloader))\n",
        "print(new_stat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWjfTuThuPJA"
      },
      "source": [
        "2. Define a Convolution Neural Network.\n",
        "[network layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HW6XRf7uPJB"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines a simple convolutional neural network (CNN) architecture\n",
        "    for image classification.\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv2d): First convolutional layer with 3 input channels (RGB),\n",
        "                           6 output channels, and a kernel size of 5x5.\n",
        "        pool (nn.MaxPool2d): Max pooling layer with a kernel size of 2x2.\n",
        "        conv2 (nn.Conv2d): Second convolutional layer with 6 input channels\n",
        "                           (from the first conv layer), 16 output channels,\n",
        "                           and a kernel size of 5x5.\n",
        "        fc1 (nn.Linear): First fully-connected layer that flattens the input\n",
        "                         from the previous convolutional layers and has 120 neurons.\n",
        "        fc2 (nn.Linear): Second fully-connected layer with 84 neurons.\n",
        "        fc3 (nn.Linear): Output layer with 10 neurons, corresponding to the 10 classes\n",
        "                         in CIFAR-10.\n",
        "\n",
        "    Methods:\n",
        "        forward(self, x): Defines the forward pass of the network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()  # Call the superclass constructor\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)  # First convolutional layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Max pooling layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # Second convolutional layer\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # First fully-connected layer\n",
        "        self.fc2 = nn.Linear(120, 84)  # Second fully-connected layer\n",
        "        self.fc3 = nn.Linear(84, 10)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the neural network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor representing the images.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor representing the class probabilities.\n",
        "        \"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # First convolutional layer with ReLU activation and pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Second convolutional layer with ReLU activation and pooling\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.shape[0],-1)  # Flatten the output from convolutional layers\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.fc1(x))  # First fully-connected layer with ReLU activation\n",
        "        x = F.relu(self.fc2(x))  # Second fully-connected layer with ReLU activation\n",
        "        x = self.fc3(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the receptive field of the network"
      ],
      "metadata": {
        "id": "O2P0Zlbl2Stb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This line attempts to clone a Git repository using a shell command.\n",
        "!git clone https://github.com/Fangyh09/pytorch-receptive-field.git\n",
        "\n",
        "# This line would move the downloaded directory\n",
        "!mv -v pytorch-receptive-field/torch_receptive_field ./\n",
        "\n",
        "# Import the 'receptive_field' function from the 'torch_receptive_field' library.\n",
        "from torch_receptive_field import receptive_field\n",
        "\n",
        "# Calculate the receptive field of the network 'net' for an input image size of\n",
        "# 3 channels (RGB) and 32x32 pixels. The 'receptive_field' function would analyze the network architecture and input size to determine\n",
        "# the receptive field size for each layer and the overall network.\n",
        "receptive_field(net, input_size=(3, 32, 32))\n"
      ],
      "metadata": {
        "id": "tsX3Q7q32SgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmA4DkACuPJB"
      },
      "source": [
        "3. Define a loss function and optimizer\n",
        "\n",
        "Let's use a Classification [Cross-Entropy](https://pytorch.org/docs/stable/nn.html#loss-functions) loss and [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl7S3NpruPJB"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim  # Import the optim module from PyTorch for optimization algorithms\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()  # Use cross-entropy loss for multi-class classification\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Explanation of the optimizer:\n",
        "#   - optim.SGD(net.parameters(), lr=0.001, momentum=0.9):\n",
        "#       - optim.SGD: This selects the Stochastic Gradient Descent (SGD) optimizer.\n",
        "#       - net.parameters(): This provides the parameters of the network (`net`) to be optimized.\n",
        "#       - lr=0.001: This sets the learning rate to 0.001 (controls how much the weights are updated).\n",
        "#       - momentum=0.9: This sets the momentum to 0.9 (a technique to improve convergence).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmu1-dvfuPJB"
      },
      "source": [
        "4. Train the network on the training data\n",
        "\n",
        "\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "928O4nWYuPJC"
      },
      "outputs": [],
      "source": [
        "num_print_intervals = 4  # Number of times to print statistics\n",
        "\n",
        "num_print_intervals+=1\n",
        "print_interval = int(len(trainloader) / num_print_intervals)\n",
        "\n",
        "# Loop over the dataset multiple times (2 epochs in this case)\n",
        "for epoch in range(2):\n",
        "    running_loss=[]  # Initialize a variable to track the total loss for this epoch\n",
        "\n",
        "    # Iterate over the training data loader\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # Get the inputs (images) and labels from the current batch\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Move the inputs and labels to the specified device (CPU or GPU)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear the gradients accumulated in the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Training loop: forward pass, backward pass, and optimization\n",
        "        # 1. Forward pass:\n",
        "        outputs = net(inputs)  # Pass the input images through the network to get predictions (outputs)\n",
        "        # 2. Calculate loss:\n",
        "        loss = criterion(outputs, labels)  # Compute the loss based on the predictions (outputs) and ground truth labels\n",
        "        # 3. Backward pass:\n",
        "        loss.backward()  # Backpropagate the loss to calculate gradients for each parameter in the network\n",
        "        # 4. Optimization step:\n",
        "        optimizer.step()  # Update the weights and biases of the network based on the calculated gradients\n",
        "\n",
        "        running_loss.append(loss.item())  # Accumulate the loss for this mini-batch\n",
        "        if i>0 and i % print_interval == 0:  # Check batch interval\n",
        "            # Print the average loss for the mini-batches\n",
        "            print('[%d, %5d] loss: %.4f' %\n",
        "                  (epoch + 1, i + 1, np.mean(running_loss)))\n",
        "            # Reset the running loss for the next interval\n",
        "            running_loss=[]\n",
        "\n",
        "# Training complete\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzpMI9aUuPJC"
      },
      "source": [
        "5. Test the network on the test data\n",
        "\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_JnNda2uPJD"
      },
      "outputs": [],
      "source": [
        "# Initialize variables to track accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Disable gradient calculation for better performance during evaluation\n",
        "with torch.no_grad():\n",
        "    # Loop over the test loader\n",
        "    for data in testloader:\n",
        "        # Get the image and label from the current batch\n",
        "        image, label = data\n",
        "\n",
        "        # Move the image data to the specified device (CPU or GPU)\n",
        "        image = image.to(device)\n",
        "\n",
        "        # Get the network's prediction for the image\n",
        "        output = net(image)\n",
        "        # smax = torch.nn.Softmax(dim=1)(output.cpu())\n",
        "\n",
        "        # Find the class with the highest probability\n",
        "        _, predicted = torch.max(output.cpu(), 1)  # Equivalent to pred = torch.argmax(output.cpu(), dim=1)\n",
        "\n",
        "        # Update total number of test images\n",
        "        total += label.size(0)  # label.size(0) gives the batch size\n",
        "\n",
        "        # Count correct predictions\n",
        "        correct += (predicted == label).sum().item()  # Count true positives\n",
        "\n",
        "# Calculate and print accuracy\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1Y4HMBOxCE6"
      },
      "source": [
        "**!HOMEWORK!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZW_s0fsB1Xi"
      },
      "source": [
        "This homework assignment asks you to performs 2 tasks:\n",
        "\n",
        "1. Analyze Results with Different Network Parameters:\n",
        "\n",
        "This involves training the network with various configurations of network parameters and analyzing the impact on performance. Here's a step-by-step approach:\n",
        "\n",
        "**Choose Network Parameters:**\n",
        "\n",
        "Select the network parameters you want to experiment with. Common choices include:\n",
        "\n",
        "Number of layers: You can try increasing or decreasing the number of layers in your chosen network architecture (e.g., convolutional layers in a CNN).\n",
        "Learning rate: Experiment with different learning rates (e.g., 0.01, 0.001, 0.0001) to find a balance between fast learning and stability.\n",
        "Other parameters: Depending on your network architecture, there might be additional options like:\n",
        "Number of filters in convolutional layers: This affects the complexity of features extracted from the data.\n",
        "Activation functions: Experiment with different activation functions (e.g., ReLU, Leaky ReLU) to introduce non-linearity.\n",
        "Optimizer parameters: Some optimizers (e.g., Adam) have hyperparameters you can adjust.\n",
        "Train the network for a different number of epochs.\n",
        "\n",
        "**Analyze Results:**\n",
        "\n",
        "Compare the performance of the network across different parameter configurations:\n",
        "\n",
        "How accuracy/loss changes with different parameter values.\n",
        "2. Show and Explain Errors of the Best Network:\n",
        "\n",
        "Once you identify the **best performing network configuration** (based on metrics like accuracy or loss), analyze its errors.\n",
        "For example you can generate a confusion matrix. This matrix visualizes how often the network predicted each class correctly or incorrectly.\n",
        "\n",
        "Useful resources:\n",
        "*   [network layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "*   [activation function](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "*   [loss functions](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}