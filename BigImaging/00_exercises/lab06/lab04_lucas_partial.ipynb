{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010770d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3a949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 16:19:05.566312: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 16:19:06.678506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753db4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, target):\n",
    "        self.data = torch.tensor(df, dtype=torch.float32).unsqueeze(1) # unsqueeze to add channel dimension\n",
    "        self.target = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # here i will return the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819c2e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 100\n",
    "experiment_name = 'lucas_01'\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a508c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/lucas_dataset_train.csv')\n",
    "df_val = pd.read_csv('data/lucas_dataset_val.csv')\n",
    "df_test = pd.read_csv('data/lucas_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d0952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13939, 4216)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>spc.400</th>\n",
       "      <th>spc.400.5</th>\n",
       "      <th>spc.401</th>\n",
       "      <th>spc.401.5</th>\n",
       "      <th>spc.402</th>\n",
       "      <th>spc.402.5</th>\n",
       "      <th>spc.403</th>\n",
       "      <th>spc.403.5</th>\n",
       "      <th>spc.404</th>\n",
       "      <th>...</th>\n",
       "      <th>sand</th>\n",
       "      <th>pH.in.CaCl2</th>\n",
       "      <th>pH.in.H2O</th>\n",
       "      <th>OC</th>\n",
       "      <th>CaCO3</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CEC</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5671</td>\n",
       "      <td>0.669077</td>\n",
       "      <td>0.676745</td>\n",
       "      <td>0.684369</td>\n",
       "      <td>0.691928</td>\n",
       "      <td>0.699396</td>\n",
       "      <td>0.706758</td>\n",
       "      <td>0.713992</td>\n",
       "      <td>0.721079</td>\n",
       "      <td>0.728002</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.15</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>39.6</td>\n",
       "      <td>54.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9008</td>\n",
       "      <td>0.679681</td>\n",
       "      <td>0.687950</td>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>0.712283</td>\n",
       "      <td>0.720136</td>\n",
       "      <td>0.727818</td>\n",
       "      <td>0.735309</td>\n",
       "      <td>0.742584</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.84</td>\n",
       "      <td>44.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>54.2</td>\n",
       "      <td>261.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9941</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.795459</td>\n",
       "      <td>0.804018</td>\n",
       "      <td>0.812496</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>0.829104</td>\n",
       "      <td>0.837181</td>\n",
       "      <td>0.845079</td>\n",
       "      <td>0.852777</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.67</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.1</td>\n",
       "      <td>216.5</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345</td>\n",
       "      <td>0.583825</td>\n",
       "      <td>0.592186</td>\n",
       "      <td>0.600491</td>\n",
       "      <td>0.608715</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.624822</td>\n",
       "      <td>0.632655</td>\n",
       "      <td>0.640310</td>\n",
       "      <td>0.647767</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.58</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4307</td>\n",
       "      <td>0.791126</td>\n",
       "      <td>0.799194</td>\n",
       "      <td>0.807208</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.822943</td>\n",
       "      <td>0.830612</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.845435</td>\n",
       "      <td>0.852549</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>6.77</td>\n",
       "      <td>7.04</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>54.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>8155</td>\n",
       "      <td>0.642357</td>\n",
       "      <td>0.650594</td>\n",
       "      <td>0.658771</td>\n",
       "      <td>0.666853</td>\n",
       "      <td>0.674813</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.690251</td>\n",
       "      <td>0.697683</td>\n",
       "      <td>0.704898</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>3.72</td>\n",
       "      <td>4.66</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13935</th>\n",
       "      <td>1636</td>\n",
       "      <td>0.922261</td>\n",
       "      <td>0.934263</td>\n",
       "      <td>0.946202</td>\n",
       "      <td>0.958037</td>\n",
       "      <td>0.969738</td>\n",
       "      <td>0.981275</td>\n",
       "      <td>0.992614</td>\n",
       "      <td>1.003729</td>\n",
       "      <td>1.014598</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.69</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>458.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13936</th>\n",
       "      <td>5012</td>\n",
       "      <td>0.705685</td>\n",
       "      <td>0.712331</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>0.725476</td>\n",
       "      <td>0.731939</td>\n",
       "      <td>0.738299</td>\n",
       "      <td>0.744541</td>\n",
       "      <td>0.750645</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.95</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13937</th>\n",
       "      <td>3820</td>\n",
       "      <td>0.821155</td>\n",
       "      <td>0.831790</td>\n",
       "      <td>0.842372</td>\n",
       "      <td>0.852866</td>\n",
       "      <td>0.863251</td>\n",
       "      <td>0.873497</td>\n",
       "      <td>0.883579</td>\n",
       "      <td>0.893470</td>\n",
       "      <td>0.903146</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.68</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>5420</td>\n",
       "      <td>0.894900</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.909957</td>\n",
       "      <td>0.917387</td>\n",
       "      <td>0.924720</td>\n",
       "      <td>0.931936</td>\n",
       "      <td>0.939010</td>\n",
       "      <td>0.945924</td>\n",
       "      <td>0.952658</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.87</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.7</td>\n",
       "      <td>38.8</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13939 rows × 4216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   spc.400  spc.400.5   spc.401  spc.401.5   spc.402  \\\n",
       "0            5671  0.669077   0.676745  0.684369   0.691928  0.699396   \n",
       "1            9008  0.679681   0.687950  0.696161   0.704279  0.712283   \n",
       "2            9941  0.786848   0.795459  0.804018   0.812496  0.820865   \n",
       "3             345  0.583825   0.592186  0.600491   0.608715  0.616834   \n",
       "4            4307  0.791126   0.799194  0.807208   0.815131  0.822943   \n",
       "...           ...       ...        ...       ...        ...       ...   \n",
       "13934        8155  0.642357   0.650594  0.658771   0.666853  0.674813   \n",
       "13935        1636  0.922261   0.934263  0.946202   0.958037  0.969738   \n",
       "13936        5012  0.705685   0.712331  0.718935   0.725476  0.731939   \n",
       "13937        3820  0.821155   0.831790  0.842372   0.852866  0.863251   \n",
       "13938        5420  0.894900   0.902452  0.909957   0.917387  0.924720   \n",
       "\n",
       "       spc.402.5   spc.403  spc.403.5   spc.404  ...  sand  pH.in.CaCl2  \\\n",
       "0       0.706758  0.713992   0.721079  0.728002  ...    75         4.78   \n",
       "1       0.720136  0.727818   0.735309  0.742584  ...    41         4.33   \n",
       "2       0.829104  0.837181   0.845079  0.852777  ...    48         6.08   \n",
       "3       0.624822  0.632655   0.640310  0.647767  ...    35         4.67   \n",
       "4       0.830612  0.838116   0.845435  0.852549  ...    50         6.77   \n",
       "...          ...       ...        ...       ...  ...   ...          ...   \n",
       "13934   0.682620  0.690251   0.697683  0.704898  ...    86         3.72   \n",
       "13935   0.981275  0.992614   1.003729  1.014598  ...    22         7.01   \n",
       "13936   0.738299  0.744541   0.750645  0.756600  ...    89         3.09   \n",
       "13937   0.873497  0.883579   0.893470  0.903146  ...    53         7.02   \n",
       "13938   0.931936  0.939010   0.945924  0.952658  ...    93         4.25   \n",
       "\n",
       "       pH.in.H2O    OC  CaCO3    N     P      K   CEC  set  \n",
       "0           5.15   8.2      0  0.9  39.6   54.6   2.8    2  \n",
       "1           4.84  44.1      0  2.5  54.2  261.8  13.8    1  \n",
       "2           6.67  22.6      0  2.3  29.1  216.5  12.8    1  \n",
       "3           5.58  21.0      0  1.5   0.0   69.8   4.7    1  \n",
       "4           7.04  38.8      6  3.0  12.1   54.3  20.5    1  \n",
       "...          ...   ...    ...  ...   ...    ...   ...  ...  \n",
       "13934       4.66  10.3      0  0.3  15.5   21.0   3.0    3  \n",
       "13935       7.69  11.3      2  1.0   0.0  458.5  22.6    3  \n",
       "13936       3.95   9.3      0  0.4   0.0   20.3   4.7    1  \n",
       "13937       7.68   6.2      1  0.7   0.0  466.0  17.1    1  \n",
       "13938       4.87  13.8      0  1.0  64.7   38.8  82.0    1  \n",
       "\n",
       "[13939 rows x 4216 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab4210",
   "metadata": {},
   "source": [
    "### Get X and y of train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2d27d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_output_features: 12 \n",
      "nr_input_features: 4202\n"
     ]
    }
   ],
   "source": [
    "# Logical array of columns\n",
    "input_cols = df_train.columns.str.contains('spc') | df_train.columns.str.contains('GPS')\n",
    "drop_cols = ['Unnamed: 0', 'set']\n",
    "\n",
    "X_train = df_train[df_train.columns[input_cols]]\n",
    "y_train = df_train[df_train.columns[~input_cols]].drop(drop_cols, axis=1)\n",
    "X_val = df_val[df_val.columns[input_cols]]\n",
    "y_val = df_val[df_val.columns[~input_cols]].drop(drop_cols, axis=1)\n",
    "X_test = df_test[df_val.columns[input_cols]]\n",
    "y_test = df_test[df_val.columns[~input_cols]].drop(drop_cols, axis=1)\n",
    "\n",
    "nr_output_features = y_train.shape[1]\n",
    "nr_input_features = X_train.shape[1]\n",
    "print('nr_output_features:', nr_output_features, '\\nnr_input_features:', nr_input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8beffc8",
   "metadata": {},
   "source": [
    "### Scale X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7711f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_val = X_scaler.transform(X_val)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "y_val = y_scaler.transform(y_val)\n",
    "y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207429cf",
   "metadata": {},
   "source": [
    "### Load train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6659a504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13939"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset(X_train, y_train)\n",
    "val_ds = Dataset(X_val, y_val)\n",
    "test_ds = Dataset(X_test, y_test)\n",
    "\n",
    "nr_features = len(train_ds)\n",
    "nr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d883e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4202])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# get first item\n",
    "inp, out = val_ds.__getitem__(100)\n",
    "# print shapes\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e2bb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first sample\n",
    "plt.plot(X_scaler.inverse_transform(inp)[0, :-2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a93fae",
   "metadata": {},
   "source": [
    "### Create train and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246c545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataloader\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers = 8\n",
    ")\n",
    "# create validation dataloader\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = False,\n",
    "    shuffle = False,\n",
    "    num_workers = 8\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = False,\n",
    "    shuffle = False,\n",
    "    num_workers = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0a7cf",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f1ab6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): LeakyReLU(negative_slope=0.01)\n",
       "    (15): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (16): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): LeakyReLU(negative_slope=0.01)\n",
       "    (18): Conv1d(512, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (19): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=33792, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=64, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=2, padding=1),       # 4202 -> 2101\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1),      # 2101 -> 1051\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),      # 1051 -> 526\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),     # 526 -> 263\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),    # 263 -> 132\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1),    # 132 -> 66\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(512, 1024, kernel_size=3, stride=2, padding=1),   # 66 -> 33\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.features2 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1),       # 4202 -> 4202\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1),      # 4202 -> 4202\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),           # 4202 -> 2101\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),      # 2101 -> 2101\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),     # 2101 -> 2101\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),           # 2101 -> 1051\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),    # 263 -> 132\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1),    # 132 -> 66\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv1d(512, 1024, kernel_size=3, stride=1, padding=1),   # 66 -> 33\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024 * 33, 512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b46630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 2101]              64\n",
      "       BatchNorm1d-2             [-1, 16, 2101]              32\n",
      "         LeakyReLU-3             [-1, 16, 2101]               0\n",
      "            Conv1d-4             [-1, 32, 1051]           1,568\n",
      "       BatchNorm1d-5             [-1, 32, 1051]              64\n",
      "         LeakyReLU-6             [-1, 32, 1051]               0\n",
      "            Conv1d-7              [-1, 64, 526]           6,208\n",
      "       BatchNorm1d-8              [-1, 64, 526]             128\n",
      "         LeakyReLU-9              [-1, 64, 526]               0\n",
      "           Conv1d-10             [-1, 128, 263]          24,704\n",
      "      BatchNorm1d-11             [-1, 128, 263]             256\n",
      "        LeakyReLU-12             [-1, 128, 263]               0\n",
      "           Conv1d-13             [-1, 256, 132]          98,560\n",
      "      BatchNorm1d-14             [-1, 256, 132]             512\n",
      "        LeakyReLU-15             [-1, 256, 132]               0\n",
      "           Conv1d-16              [-1, 512, 66]         393,728\n",
      "      BatchNorm1d-17              [-1, 512, 66]           1,024\n",
      "        LeakyReLU-18              [-1, 512, 66]               0\n",
      "           Conv1d-19             [-1, 1024, 33]       1,573,888\n",
      "      BatchNorm1d-20             [-1, 1024, 33]           2,048\n",
      "        LeakyReLU-21             [-1, 1024, 33]               0\n",
      "           Linear-22                  [-1, 512]      17,302,016\n",
      "          Dropout-23                  [-1, 512]               0\n",
      "        LeakyReLU-24                  [-1, 512]               0\n",
      "           Linear-25                   [-1, 64]          32,832\n",
      "          Dropout-26                   [-1, 64]               0\n",
      "        LeakyReLU-27                   [-1, 64]               0\n",
      "           Linear-28                   [-1, 12]             780\n",
      "================================================================\n",
      "Total params: 19,438,412\n",
      "Trainable params: 19,438,412\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 5.41\n",
      "Params size (MB): 74.15\n",
      "Estimated Total Size (MB): 79.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, (1, 4202))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326061e4",
   "metadata": {},
   "source": [
    "Define a loss function and optimizer\n",
    "\n",
    "Let's use a Regression [L1Loss](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html) loss and [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) optimizer. [learning rate scheduler](https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863#fad1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5aec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim  # Optimization algorithms for training the model\n",
    "from scipy.stats import spearmanr, pearsonr  # Statistical functions for correlation calculation\n",
    "import itertools  # Utility functions for generating combinations\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # Learning rate scheduler for training\n",
    "\n",
    "\n",
    "# Define training parameters (epochs, loss function, optimizer, and scheduler)\n",
    "epochs = 50  # Number of training epochs\n",
    "# criterion = F.mse_loss()  # L1 loss function for regression (mean absolute error)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)  # Adam optimizer with learning rate 0.001\n",
    "scheduler = CosineAnnealingLR(optimizer,\n",
    "                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n",
    "                              eta_min=1e-5)  # Minimum learning rate for scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858afdf",
   "metadata": {},
   "source": [
    "### Define train and validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "403c4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, verbose=False):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, gt in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = F.mse_loss(outputs, gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def validate(net, val_loader, verbose=False):\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    losses = []\n",
    "    for inputs, gt in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = net(inputs)\n",
    "            loss = F.mse_loss(out, gt)\n",
    "            val_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "    if verbose:\n",
    "        print(f'Loss: {np.mean(losses):.4f}, std: {np.std(losses):.4f}, min: {np.min(losses):.4f}, max: {np.max(losses):.4f}')\n",
    "\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "def exit_condition(best_value, running_loss, val_loss, epoch, no_improv):\n",
    "    if best_value is None or running_loss < best_value:\n",
    "        best_value = running_loss\n",
    "        torch.save(net.state_dict(), f'./models/{experiment_name}.pth')\n",
    "        no_improv = 0\n",
    "\n",
    "    # Early stopping due to overfitting\n",
    "    if running_loss < val_loss * 0.9 and epoch > 20:\n",
    "        print('Early stopping due to overfitting')\n",
    "        return True\n",
    "    if running_loss > best_value:\n",
    "        no_improv += 1\n",
    "        if no_improv > 10:\n",
    "            print('Early stopping due to no improvement')\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fb303",
   "metadata": {},
   "source": [
    "### Perform training with fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f91b23e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.465110 - Val Loss: 0.376777: 100%|██████████| 50/50 [03:14<00:00,  3.89s/it]\n"
     ]
    }
   ],
   "source": [
    "best_value = None\n",
    "no_improv = 0\n",
    "try:\n",
    "    pbar.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pbar = tqdm(total=epochs, desc='Training', leave=True) # Progress bar for training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = train(net, trainloader)\n",
    "\n",
    "    val_loss = validate(net, valloader)\n",
    "\n",
    "    writer.add_scalar('Epoch', epoch, epoch)\n",
    "    writer.add_scalars('Loss/epoch', {'train': running_loss, 'val': val_loss}, epoch)\n",
    "\n",
    "    pbar.set_description(f'Training - Loss: {running_loss:.4f} - Val Loss: {val_loss:.4f} \\nBest loss: {best_value:.4f} - Nr epochs no improvement: {no_improv}')\n",
    "\n",
    "    if exit_condition(best_value=best_value, running_loss=running_loss, val_loss=val_loss, epoch=epoch, no_improv=no_improv):\n",
    "        break\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa43db",
   "metadata": {},
   "source": [
    "### Test on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20674d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4016, std: 0.0956, min: 0.2791, max: 0.6766\n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(net, testloader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6be3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
