{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010770d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3a949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 12:32:44.380169: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 12:32:45.007418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753db4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, target):\n",
    "        self.data = torch.tensor(df.values, dtype=torch.float32)\n",
    "        self.target = torch.tensor(target.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # here i will return the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819c2e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "learning_rate = 0.00001\n",
    "batch_size = 100\n",
    "experiment_name = 'lucas_01'\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a508c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/lucas_dataset_train.csv')\n",
    "df_val = pd.read_csv('data/lucas_dataset_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d0952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13939, 4216)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>spc.400</th>\n",
       "      <th>spc.400.5</th>\n",
       "      <th>spc.401</th>\n",
       "      <th>spc.401.5</th>\n",
       "      <th>spc.402</th>\n",
       "      <th>spc.402.5</th>\n",
       "      <th>spc.403</th>\n",
       "      <th>spc.403.5</th>\n",
       "      <th>spc.404</th>\n",
       "      <th>...</th>\n",
       "      <th>sand</th>\n",
       "      <th>pH.in.CaCl2</th>\n",
       "      <th>pH.in.H2O</th>\n",
       "      <th>OC</th>\n",
       "      <th>CaCO3</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>CEC</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5671</td>\n",
       "      <td>0.669077</td>\n",
       "      <td>0.676745</td>\n",
       "      <td>0.684369</td>\n",
       "      <td>0.691928</td>\n",
       "      <td>0.699396</td>\n",
       "      <td>0.706758</td>\n",
       "      <td>0.713992</td>\n",
       "      <td>0.721079</td>\n",
       "      <td>0.728002</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.15</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>39.6</td>\n",
       "      <td>54.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9008</td>\n",
       "      <td>0.679681</td>\n",
       "      <td>0.687950</td>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>0.712283</td>\n",
       "      <td>0.720136</td>\n",
       "      <td>0.727818</td>\n",
       "      <td>0.735309</td>\n",
       "      <td>0.742584</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.84</td>\n",
       "      <td>44.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>54.2</td>\n",
       "      <td>261.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9941</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.795459</td>\n",
       "      <td>0.804018</td>\n",
       "      <td>0.812496</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>0.829104</td>\n",
       "      <td>0.837181</td>\n",
       "      <td>0.845079</td>\n",
       "      <td>0.852777</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>6.08</td>\n",
       "      <td>6.67</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.1</td>\n",
       "      <td>216.5</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345</td>\n",
       "      <td>0.583825</td>\n",
       "      <td>0.592186</td>\n",
       "      <td>0.600491</td>\n",
       "      <td>0.608715</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.624822</td>\n",
       "      <td>0.632655</td>\n",
       "      <td>0.640310</td>\n",
       "      <td>0.647767</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.58</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4307</td>\n",
       "      <td>0.791126</td>\n",
       "      <td>0.799194</td>\n",
       "      <td>0.807208</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.822943</td>\n",
       "      <td>0.830612</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.845435</td>\n",
       "      <td>0.852549</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>6.77</td>\n",
       "      <td>7.04</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>54.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>8155</td>\n",
       "      <td>0.642357</td>\n",
       "      <td>0.650594</td>\n",
       "      <td>0.658771</td>\n",
       "      <td>0.666853</td>\n",
       "      <td>0.674813</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.690251</td>\n",
       "      <td>0.697683</td>\n",
       "      <td>0.704898</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>3.72</td>\n",
       "      <td>4.66</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13935</th>\n",
       "      <td>1636</td>\n",
       "      <td>0.922261</td>\n",
       "      <td>0.934263</td>\n",
       "      <td>0.946202</td>\n",
       "      <td>0.958037</td>\n",
       "      <td>0.969738</td>\n",
       "      <td>0.981275</td>\n",
       "      <td>0.992614</td>\n",
       "      <td>1.003729</td>\n",
       "      <td>1.014598</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.69</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>458.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13936</th>\n",
       "      <td>5012</td>\n",
       "      <td>0.705685</td>\n",
       "      <td>0.712331</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>0.725476</td>\n",
       "      <td>0.731939</td>\n",
       "      <td>0.738299</td>\n",
       "      <td>0.744541</td>\n",
       "      <td>0.750645</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.95</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13937</th>\n",
       "      <td>3820</td>\n",
       "      <td>0.821155</td>\n",
       "      <td>0.831790</td>\n",
       "      <td>0.842372</td>\n",
       "      <td>0.852866</td>\n",
       "      <td>0.863251</td>\n",
       "      <td>0.873497</td>\n",
       "      <td>0.883579</td>\n",
       "      <td>0.893470</td>\n",
       "      <td>0.903146</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.68</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>5420</td>\n",
       "      <td>0.894900</td>\n",
       "      <td>0.902452</td>\n",
       "      <td>0.909957</td>\n",
       "      <td>0.917387</td>\n",
       "      <td>0.924720</td>\n",
       "      <td>0.931936</td>\n",
       "      <td>0.939010</td>\n",
       "      <td>0.945924</td>\n",
       "      <td>0.952658</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.87</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.7</td>\n",
       "      <td>38.8</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13939 rows × 4216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   spc.400  spc.400.5   spc.401  spc.401.5   spc.402  \\\n",
       "0            5671  0.669077   0.676745  0.684369   0.691928  0.699396   \n",
       "1            9008  0.679681   0.687950  0.696161   0.704279  0.712283   \n",
       "2            9941  0.786848   0.795459  0.804018   0.812496  0.820865   \n",
       "3             345  0.583825   0.592186  0.600491   0.608715  0.616834   \n",
       "4            4307  0.791126   0.799194  0.807208   0.815131  0.822943   \n",
       "...           ...       ...        ...       ...        ...       ...   \n",
       "13934        8155  0.642357   0.650594  0.658771   0.666853  0.674813   \n",
       "13935        1636  0.922261   0.934263  0.946202   0.958037  0.969738   \n",
       "13936        5012  0.705685   0.712331  0.718935   0.725476  0.731939   \n",
       "13937        3820  0.821155   0.831790  0.842372   0.852866  0.863251   \n",
       "13938        5420  0.894900   0.902452  0.909957   0.917387  0.924720   \n",
       "\n",
       "       spc.402.5   spc.403  spc.403.5   spc.404  ...  sand  pH.in.CaCl2  \\\n",
       "0       0.706758  0.713992   0.721079  0.728002  ...    75         4.78   \n",
       "1       0.720136  0.727818   0.735309  0.742584  ...    41         4.33   \n",
       "2       0.829104  0.837181   0.845079  0.852777  ...    48         6.08   \n",
       "3       0.624822  0.632655   0.640310  0.647767  ...    35         4.67   \n",
       "4       0.830612  0.838116   0.845435  0.852549  ...    50         6.77   \n",
       "...          ...       ...        ...       ...  ...   ...          ...   \n",
       "13934   0.682620  0.690251   0.697683  0.704898  ...    86         3.72   \n",
       "13935   0.981275  0.992614   1.003729  1.014598  ...    22         7.01   \n",
       "13936   0.738299  0.744541   0.750645  0.756600  ...    89         3.09   \n",
       "13937   0.873497  0.883579   0.893470  0.903146  ...    53         7.02   \n",
       "13938   0.931936  0.939010   0.945924  0.952658  ...    93         4.25   \n",
       "\n",
       "       pH.in.H2O    OC  CaCO3    N     P      K   CEC  set  \n",
       "0           5.15   8.2      0  0.9  39.6   54.6   2.8    2  \n",
       "1           4.84  44.1      0  2.5  54.2  261.8  13.8    1  \n",
       "2           6.67  22.6      0  2.3  29.1  216.5  12.8    1  \n",
       "3           5.58  21.0      0  1.5   0.0   69.8   4.7    1  \n",
       "4           7.04  38.8      6  3.0  12.1   54.3  20.5    1  \n",
       "...          ...   ...    ...  ...   ...    ...   ...  ...  \n",
       "13934       4.66  10.3      0  0.3  15.5   21.0   3.0    3  \n",
       "13935       7.69  11.3      2  1.0   0.0  458.5  22.6    3  \n",
       "13936       3.95   9.3      0  0.4   0.0   20.3   4.7    1  \n",
       "13937       7.68   6.2      1  0.7   0.0  466.0  17.1    1  \n",
       "13938       4.87  13.8      0  1.0  64.7   38.8  82.0    1  \n",
       "\n",
       "[13939 rows x 4216 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab4210",
   "metadata": {},
   "source": [
    "### Get X and y of train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2d27d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_output_features: 14 \n",
      "nr_input_features: 4202\n"
     ]
    }
   ],
   "source": [
    "# Logical array of columns\n",
    "input_cols = df_train.columns.str.contains('spc') | df_train.columns.str.contains('GPS')\n",
    "\n",
    "X_train = df_train[df_train.columns[input_cols]]\n",
    "y_train = df_train[df_train.columns[~input_cols]]\n",
    "X_val = df_val[df_val.columns[input_cols]]\n",
    "y_val = df_val[df_val.columns[~input_cols]]\n",
    "\n",
    "nr_output_features = sum(~input_cols)\n",
    "nr_input_features = sum(input_cols)\n",
    "print('nr_output_features:', nr_output_features, '\\nnr_input_features:', nr_input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207429cf",
   "metadata": {},
   "source": [
    "### Load train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6659a504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13939"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset(X_train, y_train)\n",
    "val_ds = Dataset(X_val, y_val)\n",
    "\n",
    "nr_features = len(train_ds)\n",
    "nr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d883e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4202])\n",
      "torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "# get first item\n",
    "inp, out = val_ds.__getitem__(10)\n",
    "# print shapes\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e2bb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot it\n",
    "plt.plot(inp[:-2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a93fae",
   "metadata": {},
   "source": [
    "### Create train and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246c545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataloader\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers = 8\n",
    ")\n",
    "# create validation dataloader\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = False,\n",
    "    shuffle = False,\n",
    "    num_workers = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0a7cf",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4f1ab6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(4202, 16, kernel_size=(3,), stride=(2,))\n",
       "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(2,))\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(2,))\n",
       "  (conv4): Conv1d(64, 128, kernel_size=(3,), stride=(2,))\n",
       "  (conv5): Conv1d(128, 256, kernel_size=(3,), stride=(2,))\n",
       "  (conv6): Conv1d(256, 512, kernel_size=(3,), stride=(2,))\n",
       "  (batchNorm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=14, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # init superclass\n",
    "        super(Net, self).__init__()\n",
    "        self.out1 = 16\n",
    "        self.out2 = self.out1 * 2 # 32\n",
    "        self.out3 = self.out2 * 2 # 64\n",
    "        self.out4 = self.out3 * 2 # 128\n",
    "        self.out5 = self.out4 * 2 # 256\n",
    "        self.out6 = self.out5 * 2 # 512\n",
    "        self.out7 = int(self.out6 / 4) # 128\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=nr_input_features, out_channels=self.out1, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out1, out_channels=self.out2, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=self.out2, out_channels=self.out3, kernel_size=3, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=self.out3, out_channels=self.out4, kernel_size=3, stride=2)\n",
    "        self.conv5 = nn.Conv1d(in_channels=self.out4, out_channels=self.out5, kernel_size=3, stride=2)\n",
    "        self.conv6 = nn.Conv1d(in_channels=self.out5, out_channels=self.out6, kernel_size=3, stride=2)\n",
    "        self.batchNorm1 = nn.BatchNorm1d(self.out1)\n",
    "        self.batchNorm2 = nn.BatchNorm1d(self.out2)\n",
    "        self.batchNorm3 = nn.BatchNorm1d(self.out3)\n",
    "        self.batchNorm4 = nn.BatchNorm1d(self.out4)\n",
    "        self.batchNorm5 = nn.BatchNorm1d(self.out5)\n",
    "        self.batchNorm6 = nn.BatchNorm1d(self.out6)\n",
    "        self.fc1 = nn.Linear(self.out6, self.out7)\n",
    "        self.fc2 = nn.Linear(self.out7, nr_output_features)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchNorm1(self.conv1(x)))\n",
    "        x = F.relu(self.batchNorm2(self.conv2(x)))\n",
    "        x = F.relu(self.batchNorm3(self.conv3(x)))\n",
    "        x = F.relu(self.batchNorm4(self.conv4(x)))\n",
    "        x = F.relu(self.batchNorm5(self.conv5(x)))\n",
    "        x = F.relu(self.batchNorm6(self.conv6(x)))\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326061e4",
   "metadata": {},
   "source": [
    "Define a loss function and optimizer\n",
    "\n",
    "Let's use a Regression [L1Loss](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html) loss and [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) optimizer. [learning rate scheduler](https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863#fad1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a5aec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim  # Optimization algorithms for training the model\n",
    "from scipy.stats import spearmanr, pearsonr  # Statistical functions for correlation calculation\n",
    "import itertools  # Utility functions for generating combinations\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # Learning rate scheduler for training\n",
    "\n",
    "\n",
    "# Define training parameters (epochs, loss function, optimizer, and scheduler)\n",
    "epochs = 50  # Number of training epochs\n",
    "# criterion = F.mse_loss()  # L1 loss function for regression (mean absolute error)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "scheduler = CosineAnnealingLR(optimizer,\n",
    "                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n",
    "                              eta_min=1e-5)  # Minimum learning rate for scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fb303",
   "metadata": {},
   "source": [
    "### Perform training with fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f91b23e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 4202, 3], expected input[1, 100, 4202] to have 4202 channels, but got 100 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(outputs, labels, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 31\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchNorm1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchNorm2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchNorm3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 4202, 3], expected input[1, 100, 4202] to have 4202 channels, but got 100 channels instead"
     ]
    }
   ],
   "source": [
    "best_value = None\n",
    "train_mse = None\n",
    "val_mse = None\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    net.train()\n",
    "    writer.add_scalar('Epoch', epoch, epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = F.mse_loss(outputs, labels, reduction='sum')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss, epoch * len(trainloader) + i)\n",
    "\n",
    "    net.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = F.mse_loss(outputs, labels, reduction='sum')\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            writer.add_scalar('Loss/val', val_running_loss, epoch * len(valloader) + i)\n",
    "\n",
    "    writer.add_scalars('Loss/epoch', {'train': running_loss, 'val': val_running_loss}, epoch)\n",
    "\n",
    "    if best_value is None or running_loss < best_value:\n",
    "        best_value = running_loss\n",
    "        torch.save(net.state_dict(), f'./models/{experiment_name}.pth')\n",
    "        print('Saved model')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20674d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
